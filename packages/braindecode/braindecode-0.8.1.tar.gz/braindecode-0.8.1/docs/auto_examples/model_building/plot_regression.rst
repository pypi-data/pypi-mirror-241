
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/model_building/plot_regression.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_model_building_plot_regression.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_model_building_plot_regression.py:


Convolutional neural network regression model on fake data.
===========================================================

This example shows how to create a CNN regressor from a CNN classifier by removing `softmax`
function from the classifier's output layer and how to train it on a fake regression dataset.

.. GENERATED FROM PYTHON SOURCE LINES 9-14

.. code-block:: default


    # Authors: Lukas Gemein <l.gemein@gmail.com>
    #          Sara Sedlar <sara.sedlar@gmail.com>
    # License: BSD-3








.. GENERATED FROM PYTHON SOURCE LINES 15-21

Fake regression data
--------------------
Function for generation of the fake regression dataset generates `n_fake_recs` recordings,
each containing sinusoidal signals with Gaussian noise. Each fake recording signal has
`n_fake_chs` channels, it lasts `fake_duration` [s] and it is sampled with `fake_sfreq` [Hz].
The recordings are split into train, validation and testing sessions.

.. GENERATED FROM PYTHON SOURCE LINES 21-29

.. code-block:: default


    import numpy as np
    import pandas as pd

    from braindecode.datasets import BaseConcatDataset, BaseDataset
    from braindecode.util import create_mne_dummy_raw









.. GENERATED FROM PYTHON SOURCE LINES 30-31

Function for generating fake regression data

.. GENERATED FROM PYTHON SOURCE LINES 31-84

.. code-block:: default

    def fake_regression_dataset(n_fake_recs, n_fake_chs, fake_sfreq,
                                fake_duration, n_fake_targets,
                                fake_data_split=[0.6, 0.2, 0.2]):
        """Generate a fake regression dataset.

        Parameters
        ----------
        n_fake_recs : int
            Number of fake recordings.
        n_fake_chs : int
            Number of fake EEG channels.
        fake_sfreq : float
            Fake sampling frequency in Hz.
        fake_duration : float
            Fake recording duration in seconds.
        n_fake_targets : int
            Number of targets.
        fake_data_split : list
            List of train/valid/test subset fractions.

        Returns
        -------
        dataset : BaseConcatDataset object
            The generated dataset object.
        """

        datasets = []
        for i in range(n_fake_recs):
            if i < int(fake_data_split[0] * n_fake_recs):
                target_subset = "train"
            elif i < int((1 - fake_data_split[2]) * n_fake_recs):
                target_subset = "valid"
            else:
                target_subset = "test"
            raw, _ = create_mne_dummy_raw(n_channels=n_fake_chs,
                                          n_times=fake_duration * fake_sfreq,
                                          sfreq=fake_sfreq)

            target = np.random.randint(0, 10, n_fake_targets)
            for j in range(n_fake_targets):
                x = np.sin(2 * np.pi * target[j] * raw.times)
                raw._data += np.expand_dims(x, axis=0)

            if n_fake_targets == 1:
                target = target[0]
            fake_description = pd.Series(data=[target, target_subset],
                                         index=["target", "session"])
            datasets.append(
                BaseDataset(raw, fake_description, target_name="target"))

        return BaseConcatDataset(datasets)









.. GENERATED FROM PYTHON SOURCE LINES 85-89

Generating fake regression dataset
-----------------------------------



.. GENERATED FROM PYTHON SOURCE LINES 89-100

.. code-block:: default

    n_fake_rec = 20
    n_fake_chans = 21
    fake_sfreq = 100
    fake_duration = 30
    n_fake_targets = 1
    dataset = fake_regression_dataset(n_fake_recs=n_fake_rec,
                                      n_fake_chs=n_fake_chans,
                                      fake_sfreq=fake_sfreq,
                                      fake_duration=fake_duration,
                                      n_fake_targets=n_fake_targets)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Creating RawArray with float64 data, n_channels=21, n_times=3000
        Range : 0 ... 2999 =      0.000 ...    29.990 secs
    Ready.
    Creating RawArray with float64 data, n_channels=21, n_times=3000
        Range : 0 ... 2999 =      0.000 ...    29.990 secs
    Ready.
    Creating RawArray with float64 data, n_channels=21, n_times=3000
        Range : 0 ... 2999 =      0.000 ...    29.990 secs
    Ready.
    Creating RawArray with float64 data, n_channels=21, n_times=3000
        Range : 0 ... 2999 =      0.000 ...    29.990 secs
    Ready.
    Creating RawArray with float64 data, n_channels=21, n_times=3000
        Range : 0 ... 2999 =      0.000 ...    29.990 secs
    Ready.
    Creating RawArray with float64 data, n_channels=21, n_times=3000
        Range : 0 ... 2999 =      0.000 ...    29.990 secs
    Ready.
    Creating RawArray with float64 data, n_channels=21, n_times=3000
        Range : 0 ... 2999 =      0.000 ...    29.990 secs
    Ready.
    Creating RawArray with float64 data, n_channels=21, n_times=3000
        Range : 0 ... 2999 =      0.000 ...    29.990 secs
    Ready.
    Creating RawArray with float64 data, n_channels=21, n_times=3000
        Range : 0 ... 2999 =      0.000 ...    29.990 secs
    Ready.
    Creating RawArray with float64 data, n_channels=21, n_times=3000
        Range : 0 ... 2999 =      0.000 ...    29.990 secs
    Ready.
    Creating RawArray with float64 data, n_channels=21, n_times=3000
        Range : 0 ... 2999 =      0.000 ...    29.990 secs
    Ready.
    Creating RawArray with float64 data, n_channels=21, n_times=3000
        Range : 0 ... 2999 =      0.000 ...    29.990 secs
    Ready.
    Creating RawArray with float64 data, n_channels=21, n_times=3000
        Range : 0 ... 2999 =      0.000 ...    29.990 secs
    Ready.
    Creating RawArray with float64 data, n_channels=21, n_times=3000
        Range : 0 ... 2999 =      0.000 ...    29.990 secs
    Ready.
    Creating RawArray with float64 data, n_channels=21, n_times=3000
        Range : 0 ... 2999 =      0.000 ...    29.990 secs
    Ready.
    Creating RawArray with float64 data, n_channels=21, n_times=3000
        Range : 0 ... 2999 =      0.000 ...    29.990 secs
    Ready.
    Creating RawArray with float64 data, n_channels=21, n_times=3000
        Range : 0 ... 2999 =      0.000 ...    29.990 secs
    Ready.
    Creating RawArray with float64 data, n_channels=21, n_times=3000
        Range : 0 ... 2999 =      0.000 ...    29.990 secs
    Ready.
    Creating RawArray with float64 data, n_channels=21, n_times=3000
        Range : 0 ... 2999 =      0.000 ...    29.990 secs
    Ready.
    Creating RawArray with float64 data, n_channels=21, n_times=3000
        Range : 0 ... 2999 =      0.000 ...    29.990 secs
    Ready.




.. GENERATED FROM PYTHON SOURCE LINES 101-106

Defining a CNN regression model
-------------------------------

Choosing and defining a CNN classifier, `ShallowFBCSPNet` or `Deep4Net`, introduced in [1]_.
To convert a classifier to a regressor, `softmax` function is removed from its output layer.

.. GENERATED FROM PYTHON SOURCE LINES 106-135

.. code-block:: default

    from braindecode.util import set_random_seeds
    from braindecode.models import Deep4Net
    from braindecode.models import ShallowFBCSPNet
    import torch

    # Choosing a CNN model
    model_name = "shallow"  # 'shallow' or 'deep'

    # Defining a CNN model
    if model_name in ["shallow", "Shallow", "ShallowConvNet"]:
        model = ShallowFBCSPNet(in_chans=n_fake_chans,
                                n_classes=n_fake_targets,
                                input_window_samples=fake_sfreq * fake_duration,
                                n_filters_time=40, n_filters_spat=40,
                                final_conv_length=35,
                                add_log_softmax=False,)
    elif model_name in ["deep", "Deep", "DeepConvNet"]:
        model = Deep4Net(in_chans=n_fake_chans, n_classes=n_fake_targets,
                         input_window_samples=fake_sfreq * fake_duration,
                         n_filters_time=25, n_filters_spat=25,
                         stride_before_pool=True,
                         n_filters_2=n_fake_chans * 2,
                         n_filters_3=n_fake_chans * 4,
                         n_filters_4=n_fake_chans * 8,
                         final_conv_length=1,
                         add_log_softmax=False, )
    else:
        raise ValueError(f'{model_name} unknown')





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/bru/PycharmProjects/braindecode-new/braindecode/models/base.py:23: UserWarning: ShallowFBCSPNet: 'in_chans' is depreciated. Use 'n_chans' instead.
      warnings.warn(
    /home/bru/PycharmProjects/braindecode-new/braindecode/models/base.py:23: UserWarning: ShallowFBCSPNet: 'n_classes' is depreciated. Use 'n_outputs' instead.
      warnings.warn(
    /home/bru/PycharmProjects/braindecode-new/braindecode/models/base.py:23: UserWarning: ShallowFBCSPNet: 'input_window_samples' is depreciated. Use 'n_times' instead.
      warnings.warn(




.. GENERATED FROM PYTHON SOURCE LINES 136-139

Choosing between GPU and CPU processors
---------------------------------------
By default, model's training and evaluation take place at GPU if it exists, otherwise on CPU.

.. GENERATED FROM PYTHON SOURCE LINES 139-150

.. code-block:: default

    cuda = torch.cuda.is_available()
    device = 'cuda' if cuda else 'cpu'
    if cuda:
        torch.backends.cudnn.benchmark = True

    # Setting a random seed
    seed = 20200220
    set_random_seeds(seed=seed, cuda=cuda)
    if cuda:
        model.cuda()








.. GENERATED FROM PYTHON SOURCE LINES 151-154

Data windowing
----------------
Windowing data with a sliding window into the epochs of the size `window_size_samples`.

.. GENERATED FROM PYTHON SOURCE LINES 154-175

.. code-block:: default

    from braindecode.models.util import to_dense_prediction_model, get_output_shape
    from braindecode.preprocessing import create_fixed_length_windows

    window_size_samples = fake_sfreq * fake_duration // 3
    to_dense_prediction_model(model)
    n_preds_per_input = get_output_shape(model, n_fake_chans, window_size_samples)[
        2]
    windows_dataset = create_fixed_length_windows(dataset,
                                                  start_offset_samples=0,
                                                  stop_offset_samples=0,
                                                  window_size_samples=window_size_samples,
                                                  window_stride_samples=n_preds_per_input,
                                                  drop_last_window=False,
                                                  preload=True)

    # Splitting windowed data into train, valid and test subsets.
    splits = windows_dataset.split("session")
    train_set = splits["train"]
    valid_set = splits["valid"]
    test_set = splits["test"]





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/bru/PycharmProjects/braindecode-2023/venv/lib/python3.9/site-packages/sklearn/utils/deprecation.py:86: FutureWarning: Function to_dense_prediction_model is deprecated; will be removed in version 1.0. Use EEGModuleMixin.to_dense_prediction_model method directly on the model object.
      warnings.warn(msg, category=FutureWarning)
    /home/bru/PycharmProjects/braindecode-2023/venv/lib/python3.9/site-packages/sklearn/utils/deprecation.py:86: FutureWarning: Function get_output_shape is deprecated; will be removed in version 1.0. Use EEGModuleMixin.get_output_shape method directly on the model object.
      warnings.warn(msg, category=FutureWarning)
    /home/bru/PycharmProjects/braindecode-new/braindecode/preprocessing/windowers.py:610: UserWarning: Meaning of `trial_stop_offset_samples`=0 has changed, use `None` to indicate end of trial/recording. Using `None`.
      warnings.warn(




.. GENERATED FROM PYTHON SOURCE LINES 176-181

Model training
-----------------
Model is trained by minimizing MSE loss between ground truth and estimated value averaged over
a period of time using AdamW optimizer [2]_, [3]_. Learning rate is managed by CosineAnnealingLR
learning rate scheduler.

.. GENERATED FROM PYTHON SOURCE LINES 181-206

.. code-block:: default

    from braindecode import EEGRegressor
    from braindecode.training.losses import CroppedLoss
    from skorch.callbacks import LRScheduler
    from skorch.helper import predefined_split

    batch_size = 4
    n_epochs = 3
    optimizer_lr = 0.001
    optimizer_weight_decay = 0.0
    regressor = EEGRegressor(model, cropped=True,
                             criterion=CroppedLoss,
                             criterion__loss_function=torch.nn.functional.mse_loss,
                             optimizer=torch.optim.AdamW,
                             optimizer__lr=optimizer_lr,
                             optimizer__weight_decay=optimizer_weight_decay,
                             train_split=predefined_split(valid_set),
                             iterator_train__shuffle=True,
                             batch_size=batch_size,
                             callbacks=["neg_root_mean_squared_error",
                                        ("lr_scheduler",
                                         LRScheduler('CosineAnnealingLR',
                                                     T_max=n_epochs - 1))],
                             device=device, )
    regressor.fit(train_set, y=None, epochs=n_epochs)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      epoch    train_loss    train_neg_root_mean_squared_error    valid_loss    valid_neg_root_mean_squared_error      lr     dur
    -------  ------------  -----------------------------------  ------------  -----------------------------------  ------  ------
          1        8.6188                              -1.3442        0.3962                              -0.6291  0.0010  0.8232
          2        1.3336                              -0.9205        0.8489                              -0.9209  0.0005  0.9232
          3        1.9584                              -0.6824        0.3750                              -0.6087  0.0000  0.8321




.. GENERATED FROM PYTHON SOURCE LINES 207-210

Model evaluation
-----------------
Plotting training and validation losses and negative root mean square error

.. GENERATED FROM PYTHON SOURCE LINES 210-228

.. code-block:: default

    import matplotlib.pyplot as plt


    fig, axes = plt.subplots(1, 2, figsize=(10, 5))
    axes[0].set_title("Train and valid losses")
    axes[0].plot(regressor.history[:, "train_loss"])
    axes[0].plot(regressor.history[:, "valid_loss"])
    axes[0].set_xlabel("Epochs")
    axes[0].set_ylabel("Cropped MSE loss")
    axes[0].legend(["Train", "Valid"])

    axes[1].set_title("Train and valid errors")
    axes[1].plot(regressor.history[:, "train_neg_root_mean_squared_error"])
    axes[1].plot(regressor.history[:, "valid_neg_root_mean_squared_error"])
    axes[1].set_xlabel("Epochs")
    axes[1].set_ylabel("Negative RMSE")
    axes[1].legend(["Train", "Valid"])




.. image-sg:: /auto_examples/model_building/images/sphx_glr_plot_regression_001.png
   :alt: Train and valid losses, Train and valid errors
   :srcset: /auto_examples/model_building/images/sphx_glr_plot_regression_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    <matplotlib.legend.Legend object at 0x7f8b79736940>



.. GENERATED FROM PYTHON SOURCE LINES 229-232

Model testing
-----------------
Plotting a scatter plot of estimated versus target values and corresponding trend line.

.. GENERATED FROM PYTHON SOURCE LINES 232-244

.. code-block:: default

    fig, axes = plt.subplots(1, 1, figsize=(5, 5))
    y_estim = np.ravel(regressor.predict(test_set))
    y_gt = test_set.get_metadata()["target"].to_numpy()

    _ = axes.scatter(y_gt, y_estim)
    _ = axes.set_ylabel("Estimated targets.")
    _ = axes.set_xlabel("Ground truth targets.")

    z = np.polyfit(y_gt, y_estim, 1)
    p = np.poly1d(z)
    plt.plot(y_gt, p(y_gt), "r--")
    plt.show()



.. image-sg:: /auto_examples/model_building/images/sphx_glr_plot_regression_002.png
   :alt: plot regression
   :srcset: /auto_examples/model_building/images/sphx_glr_plot_regression_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 245-258

References
----------

.. [1] Schirrmeister, R. T., Springenberg, J. T., Fiederer, L. D. J., Glasstetter, M.,
       Eggensperger, K., Tangermann, M., ... & Ball, T. (2017).
       Deep learning with convolutional neural networks for EEG decoding and visualization.
       Human brain mapping, 38(11), 5391-5420.

.. [2] Kingma, Diederik P., and Jimmy Ba.
       "Adam: A method for stochastic optimization." arXiv preprint arXiv:1412.6980 (2014).

.. [3] Reddi, Sashank J., Satyen Kale, and Sanjiv Kumar.
       "On the convergence of adam and beyond." arXiv preprint arXiv:1904.09237 (2019).


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 6.678 seconds)

**Estimated memory usage:**  78 MB


.. _sphx_glr_download_auto_examples_model_building_plot_regression.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_regression.py <plot_regression.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_regression.ipynb <plot_regression.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_

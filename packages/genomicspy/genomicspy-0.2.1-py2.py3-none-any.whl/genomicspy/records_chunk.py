"""Chunk.py"""

# class for Chunk (used in dedup_rename_gts_vcfpy.py)

from __future__ import annotations
import pickle
import os
from collections.abc import Collection, Iterable
import pandas as pd
import vcfpy

from oddsnends import sort_levels

__all__ = ["Chunk"]


class Chunk:
    """Class for handling chunks of vcfpy.Records"""

    DEFAULT_ID_NAME = "CHUNK_GT"

    def __init__(
        self,
        records: Collection[vcfpy.Record] = None,
        pos: int = None,
        anns: dict = None,
        **kwargs,
    ) -> None:
        # self._records = records
        self._pos = pos
        self._anns = {} if anns is None else anns

        # init other attributes
        self._gts = None
        self._seqids = None
        self._meta = None
        self._id_name = self.DEFAULT_ID_NAME

        if records is not None:
            self.process_records(records, inplace=True, **kwargs)

    def __len__(self):
        return self.nsites

    @staticmethod
    def group_assign_id(data: pd.DataFrame, id_name: str = "INDEX") -> pd.DataFrame:
        """Group identical rows and assign unique index ID, sorts by min row sum

        Returns: pd.DataFrame with values dist and INDEX,
            index.values as data values, index.names as data.columns
        """
        # parse rows
        grouped = (
            data.groupby(data.columns.to_list(), dropna=False)
            .apply(lambda g: g.index)
            .apply(list)
            .rename(data.index.name)
            .pipe(sort_levels)
        )

        ## Assign ids
        # sort by row sum
        ids = grouped.index.to_frame().pipe(
            lambda df: df.rename(dict((c, i) for i, c in enumerate(df.columns)), axis=1)
        )

        # calculate and sort by distance (num differences) from ref
        ids = (
            ids.assign(dist=ids.sum(axis=1))
            .sort_values(["dist", *ids.columns])
            .drop(ids.columns, axis=1)
        )

        non_refs = ids.loc[ids.dist > 0].pipe(
            lambda df: df.assign(**{id_name: range(1, len(df) + 1)})
        )

        ref = ids.loc[ids.dist == 0].assign(**{id_name: 0})

        combined = pd.concat([grouped, pd.concat([ref, non_refs], axis=0)], axis=1)
        combined.sort_values(id_name, inplace=True)
        return combined

    def process_records(
        self,
        records: Iterable[vcfpy.Record],
        pos: int = None,
        gt_allele_idx: int = 0,
        id_name: str = None,
        inplace: bool = True,
    ) -> dict | None:
        """Process chunk of vcfpy.Records obtained from reader
        default id_name is Chunk.ID_NAME
        """
        # assert self._records is not None, "chunk.records not initialized"

        if pos is not None:
            self._pos = pos

        if id_name is None:
            id_name = self._id_name
        else:
            self._id_name = id_name

        # if len(self._records) == 0:
        if len(records) == 0:
            # hack together empty dataframes
            meta_cols = ["dist", "SEQID"]  # dist is from group_assign_id()

            idx_id_name = pd.Index([], name=id_name)
            multix_chrom_pos = pd.MultiIndex.from_tuples([], names=["CHROM", "POS"])

            gts = pd.DataFrame(index=idx_id_name, columns=multix_chrom_pos)
            meta = pd.DataFrame(index=idx_id_name, columns=meta_cols)
            seqids = pd.DataFrame(index=pd.Index([], name="SEQID"), columns=[id_name])
        else:
            # extract info from calls
            calls = pd.DataFrame(
                (
                    [rec.CHROM, rec.POS, call.gt_alleles[gt_allele_idx], call.sample]
                    for rec in records
                    for call in rec
                    # ] for rec in self.records for call in rec
                ),
                columns=["CHROM", "POS", "GT", "SEQID"],
            )

            chunk = calls.pivot_table(
                "GT", "SEQID", ["CHROM", "POS"], lambda x: x
            ).pipe(self.group_assign_id, id_name=id_name)

            # dataframe with values GTs, index CHUNK_GT, columns (CHROM, POS)
            gts = chunk.index.to_frame().join(chunk[id_name]).set_index(id_name)

            gts.columns = pd.MultiIndex.from_tuples(
                gts.columns.values, names=["CHROM", "POS"]
            )

            meta = chunk.set_index(id_name).pipe(
                lambda df: df[[*df.columns.drop("SEQID"), "SEQID"]]
            )

            # dataframe with values SEQID, CHUNK_GT
            seqids = (
                chunk[[id_name, "SEQID"]]
                .explode("SEQID", ignore_index=True)
                .set_index("SEQID")
            )

        if self._pos is not None:
            gts = pd.concat({self._pos: gts}, names=["CHUNK_POS"])
            meta = pd.concat({self._pos: meta}, names=["CHUNK_POS"])

        if inplace:
            self._gts = gts
            self._seqids = seqids
            self._meta = meta

            return

        return {"gts": gts, "seqids": seqids, "meta": meta}

    def to_pickle(self, fpath, **kwargs) -> None:
        """Save as pickle. file is either fpath or object with write attribute.
        **kwargs passed to pickle.dump
        """
        try:
            os.makedirs(os.path.dirname(fpath), exist_ok=True)
            fpath.write(pickle.dumps(self, **kwargs))

        except (AttributeError, TypeError):
            os.makedirs(os.path.dirname(fpath), exist_ok=True)
            with open(fpath, "wb") as fout:
                fout.write(pickle.dumps(self, **kwargs))

    @property
    def anns(self):
        """Annotations"""
        return self._anns

    @property
    def pos(self):
        """Chunk "position" number"""
        return self._pos

    @pos.setter
    def pos(self, value) -> None:
        if self._gts is not None:
            self._gts.rename({self._pos: value}, axis=0, level="CHUNK_POS")
        if self._meta is not None:
            self._meta.rename({self._pos: value}, axis=0, level="CHUNK_POS")
        self._pos = value

    @property
    def id_name(self):
        """Returns name used for chunk id"""
        return self._id_name

    @id_name.setter
    def id_name(self, value) -> None:
        if self._gts is not None:
            self._gts.rename_axis({self._id_name: value}, axis=0, inplace=True)
        if self._meta is not None:
            self._meta.rename_axis({self._id_name: value}, axis=0, inplace=True)
        if self._seqids is not None:
            self._seqids.rename({self._id_name: value}, axis=1, inplace=True)
        self._id_name = value

    @property
    def gts(self):
        """DataFrame of chunk gt index and genotypes"""
        return self._gts

    @property
    def meta(self):
        """DataFrame of chunk gt indx to metadata (dist, seqid list)"""
        return self._meta

    @property
    def seqids(self):
        """DataFrame of seqid to chunk gt index"""
        return self._seqids

    @property
    def shape(self):
        """Returns shape as (num. of sites, num. of genotype combinations)"""
        return None if self._gts is None else self._gts.shape[::-1]

    @property
    def nsamples(self):
        """Returns number of sequences"""
        return None if self._seqids is None else len(self._seqids)

    @property
    def nsites(self):
        """Returns number of sites"""
        return None if self._gts is None else len(self._gts.columns)

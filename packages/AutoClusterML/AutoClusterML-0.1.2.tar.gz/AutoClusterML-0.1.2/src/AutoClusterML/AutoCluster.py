from sklearn.cluster import *
from sklearn.metrics import *
from sklearn.metrics.cluster import *
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import *

def dim_reducer(data,method=None,components=None):
    if method=='PCA':
        n=PCA(n_components=components)
        data=n.fit_transform(data)
    elif method=='factor analysis':
        n=FactorAnalysis(n_components=components)
        data=n.fit_transform(data)
    elif method=='ICA':
        n=FastICA(n_components=components)
        data=n.fit_transform(data)
    elif method=='Incremental PCA':
        n=IncrementalPCA(n_components=components)
        data=n.fit_transform(data)
    elif method=='Kernel PCA':
        n=KernelPCA(n_components=components)
        data=n.fit_transform(data)
    elif method=='Mini Batch Sparse PCA':
        n=MiniBatchSparsePCA(n_components=components)
        data=n.fit_transform(data)
    elif method=='NMF':
        n=NMF(n_components=components)
        data=n.fit_transform(data)
    elif method=='Sparse PCA':
        n=SparsePCA(n_components=components)
        data=n.fit_transform(data)
    elif method=='Mini Batch NMF':
        n=MiniBatchNMF(n_components=components)
        data=n.fit_transform(data)
    elif method=='SVD':
        n=TruncatedSVD(n_components=components)
        data=n.fit_transform(data)
    else:
        n=PCA(n_components=components)
        data=n.fit_transform(data)
    return data
def autocluster(data,labels=None,clusters=None):
    if labels is None:
        model=['kmeans','kmeans-elkan','bisectingkmeans','bisectingkmeans-elkan','minibatchkmeans','agglomerative','agglomerative-single','agglomerative-complete','agglomerative-average','birch-0.05','birch-0.1','birch-0.5','spectral']
        dat=pd.DataFrame(columns=['model','size','silhouette','davies-bouldin','calinski-harabasz','labels'])
        dat['model']=model
        dat['size']=clusters
        silhouette=[]
        davies=[]
        calinski=[]
        label=[]
        for i in model:
            if i=='kmeans':
                m=KMeans(n_clusters=clusters)
                m.fit(data)
                a=m.labels_
                s=silhouette_score(data,a)
                d=davies_bouldin_score(data,a)
                c=calinski_harabasz_score(data,a)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                label.append(a)
            elif i=='kmeans-elkan':
                m=KMeans(n_clusters=clusters,algorithm='elkan')
                m.fit(data)
                a=m.labels_
                s=silhouette_score(data,a)
                d=davies_bouldin_score(data,a)
                c=calinski_harabasz_score(data,a)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                label.append(a)
            elif i=='bisectingkmeans':
                m=BisectingKMeans(n_clusters=clusters)
                m.fit(data)
                a=m.labels_
                s=silhouette_score(data,a)
                d=davies_bouldin_score(data,a)
                c=calinski_harabasz_score(data,a)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                label.append(a)
            elif i=='bisectingkmeans-elkan':
                m=BisectingKMeans(n_clusters=clusters,algorithm='elkan')
                m.fit(data)
                a=m.labels_
                s=silhouette_score(data,a)
                d=davies_bouldin_score(data,a)
                c=calinski_harabasz_score(data,a)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                label.append(a)
            elif i=='minibatchkmeans':
                m=MiniBatchKMeans(n_clusters=clusters)
                m.fit(data)
                a=m.labels_
                s=silhouette_score(data,a)
                d=davies_bouldin_score(data,a)
                c=calinski_harabasz_score(data,a)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                label.append(a)
            elif i=='agglomerative':
                mn=AgglomerativeClustering(n_clusters=clusters).fit_predict(data)
                s=silhouette_score(data,mn)
                d=davies_bouldin_score(data,mn)
                c=calinski_harabasz_score(data,mn)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                label.append(mn)
            elif i=='agglomerative-single':
                mn=AgglomerativeClustering(n_clusters=clusters,linkage='single').fit_predict(data)
                s=silhouette_score(data,mn)
                d=davies_bouldin_score(data,mn)
                c=calinski_harabasz_score(data,mn)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                label.append(mn)
            elif i=='agglomerative-complete':
                mn=AgglomerativeClustering(n_clusters=clusters,linkage='complete').fit_predict(data)
                s=silhouette_score(data,mn)
                d=davies_bouldin_score(data,mn)
                c=calinski_harabasz_score(data,mn)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                label.append(mn)
            elif i=='agglomerative-average':
                mn=AgglomerativeClustering(n_clusters=clusters,linkage='average').fit_predict(data)
                s=silhouette_score(data,mn)
                d=davies_bouldin_score(data,mn)
                c=calinski_harabasz_score(data,mn)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                label.append(mn)
            elif i=='birch-0.05':
                m=Birch(n_clusters=clusters,threshold=0.05)
                m.fit(data)
                a=m.labels_
                s=silhouette_score(data,a)
                d=davies_bouldin_score(data,a)
                c=calinski_harabasz_score(data,a)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                label.append(a)
            elif i=='birch-0.1':
                m=Birch(n_clusters=clusters,threshold=0.05)
                m.fit(data)
                a=m.labels_
                s=silhouette_score(data,a)
                d=davies_bouldin_score(data,a)
                c=calinski_harabasz_score(data,a)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                label.append(a)
            elif i=='birch-0.5':
                m=Birch(n_clusters=clusters,threshold=0.05)
                m.fit(data)
                a=m.labels_
                s=silhouette_score(data,a)
                d=davies_bouldin_score(data,a)
                c=calinski_harabasz_score(data,a)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                label.append(a)
            elif i=='spectral':
                m=SpectralClustering(n_clusters=clusters)
                m.fit(data)
                a=m.labels_
                s=silhouette_score(data,a)
                d=davies_bouldin_score(data,a)
                c=calinski_harabasz_score(data,a)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                label.append(a)
        dat['silhouette']=silhouette
        dat['davies-bouldin']=davies
        dat['calinski-harabasz']=calinski
        dat['labels']=label
        dat=dat.sort_values(by=['silhouette'])
        return dat
    else:
        model=['kmeans','kmeans-elkan','bisectingkmeans','bisectingkmeans-elkan','minibatchkmeans','agglomerative','agglomerative-single','agglomerative-complete','agglomerative-average','birch-0.05','birch-0.1','birch-0.5','spectral']
        dat=pd.DataFrame(columns=['model','size','accuracy','precision','recall','f1','rand','adjusted rand','mutual info','adjusted mutual info','fowlkes mallows','homogeneity measure','v measure','silhouette','davies-bouldin','calinski-harabasz','contingency matrix','confusion matrix','labels'])
        dat['model']=model
        dat['size']=clusters
        accuracy=[]
        precision=[]
        recall=[]
        f1=[]
        rand=[]
        adjusted_rand=[]
        mutual_info=[]
        adjusted_mutual_info=[]
        fowlkes_mallows=[]
        homogeneity=[]
        v_measure=[]
        silhouette=[]
        davies=[]
        calinski=[]
        contigencymatrix=[]
        confusion_matrix=[]
        label=[]
        for i in model:
            if i=='kmeans':
                m=KMeans(n_clusters=clusters)
                m.fit(data)
                a=m.labels_
                acc=accuracy_score(a,labels)
                p=precision_score(a,labels,average='micro')
                r=recall_score(a,labels,average='micro')
                f=f1_score(a,labels,average='micro')
                rands=rand_score(a,labels)
                ad_rands=adjusted_rand_score(a,labels)
                mut=mutual_info_score(a,labels)
                ad_mut=adjusted_mutual_info_score(a,labels)
                fowlkes=fowlkes_mallows_score(a,labels)
                hom=homogeneity_score(a,labels)
                v=v_measure_score(a,labels)
                s=silhouette_score(data,a)
                d=davies_bouldin_score(data,a)
                c=calinski_harabasz_score(data,a)
                con=contingency_matrix(a,labels)
                cm=pair_confusion_matrix(a,labels)
                accuracy.append(acc)
                precision.append(p)
                recall.append(r)
                f1.append(f)
                rand.append(rands)
                adjusted_rand.append(ad_rands)
                mutual_info.append(mut)
                adjusted_mutual_info.append(ad_mut)
                fowlkes_mallows.append(fowlkes)
                homogeneity.append(hom)
                v_measure.append(v)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                contigencymatrix.append(con)
                confusion_matrix.append(cm)
                label.append(a)
            elif i=='kmeans-elkan':
                m=KMeans(n_clusters=clusters,algorithm='elkan')
                m.fit(data)
                a=m.labels_
                acc=accuracy_score(a,labels)
                p=precision_score(a,labels,average='micro')
                r=recall_score(a,labels,average='micro')
                f=f1_score(a,labels,average='micro')
                rands=rand_score(a,labels)
                ad_rands=adjusted_rand_score(a,labels)
                mut=mutual_info_score(a,labels)
                ad_mut=adjusted_mutual_info_score(a,labels)
                fowlkes=fowlkes_mallows_score(a,labels)
                hom=homogeneity_score(a,labels)
                v=v_measure_score(a,labels)
                s=silhouette_score(data,a)
                d=davies_bouldin_score(data,a)
                c=calinski_harabasz_score(data,a)
                con=contingency_matrix(a,labels)
                cm=pair_confusion_matrix(a,labels)
                accuracy.append(acc)
                precision.append(p)
                recall.append(r)
                f1.append(f)
                rand.append(rands)
                adjusted_rand.append(ad_rands)
                mutual_info.append(mut)
                adjusted_mutual_info.append(ad_mut)
                fowlkes_mallows.append(fowlkes)
                homogeneity.append(hom)
                v_measure.append(v)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                contigencymatrix.append(con)
                confusion_matrix.append(cm)
                label.append(a)
            elif i=='bisectingkmeans':
                m=BisectingKMeans(n_clusters=clusters)
                m.fit(data)
                a=m.labels_
                acc=accuracy_score(a,labels)
                p=precision_score(a,labels,average='micro')
                r=recall_score(a,labels,average='micro')
                f=f1_score(a,labels,average='micro')
                rands=rand_score(a,labels)
                ad_rands=adjusted_rand_score(a,labels)
                mut=mutual_info_score(a,labels)
                ad_mut=adjusted_mutual_info_score(a,labels)
                fowlkes=fowlkes_mallows_score(a,labels)
                hom=homogeneity_score(a,labels)
                v=v_measure_score(a,labels)
                s=silhouette_score(data,a)
                d=davies_bouldin_score(data,a)
                c=calinski_harabasz_score(data,a)
                con=contingency_matrix(a,labels)
                cm=pair_confusion_matrix(a,labels)
                accuracy.append(acc)
                precision.append(p)
                recall.append(r)
                f1.append(f)
                rand.append(rands)
                adjusted_rand.append(ad_rands)
                mutual_info.append(mut)
                adjusted_mutual_info.append(ad_mut)
                fowlkes_mallows.append(fowlkes)
                homogeneity.append(hom)
                v_measure.append(v)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                contigencymatrix.append(con)
                confusion_matrix.append(cm)
                label.append(a)
            elif i=='bisectingkmeans-elkan':
                m=BisectingKMeans(n_clusters=clusters,algorithm='elkan')
                m.fit(data)
                a=m.labels_
                acc=accuracy_score(a,labels)
                p=precision_score(a,labels,average='micro')
                r=recall_score(a,labels,average='micro')
                f=f1_score(a,labels,average='micro')
                rands=rand_score(a,labels)
                ad_rands=adjusted_rand_score(a,labels)
                mut=mutual_info_score(a,labels)
                ad_mut=adjusted_mutual_info_score(a,labels)
                fowlkes=fowlkes_mallows_score(a,labels)
                hom=homogeneity_score(a,labels)
                v=v_measure_score(a,labels)
                s=silhouette_score(data,a)
                d=davies_bouldin_score(data,a)
                c=calinski_harabasz_score(data,a)
                con=contingency_matrix(a,labels)
                cm=pair_confusion_matrix(a,labels)
                accuracy.append(acc)
                precision.append(p)
                recall.append(r)
                f1.append(f)
                rand.append(rands)
                adjusted_rand.append(ad_rands)
                mutual_info.append(mut)
                adjusted_mutual_info.append(ad_mut)
                fowlkes_mallows.append(fowlkes)
                homogeneity.append(hom)
                v_measure.append(v)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                contigencymatrix.append(con)
                confusion_matrix.append(cm)
                label.append(a)
            elif i=='minibatchkmeans':
                m=MiniBatchKMeans(n_clusters=clusters)
                m.fit(data)
                a=m.labels_
                acc=accuracy_score(a,labels)
                p=precision_score(a,labels,average='micro')
                r=recall_score(a,labels,average='micro')
                f=f1_score(a,labels,average='micro')
                rands=rand_score(a,labels)
                ad_rands=adjusted_rand_score(a,labels)
                mut=mutual_info_score(a,labels)
                ad_mut=adjusted_mutual_info_score(a,labels)
                fowlkes=fowlkes_mallows_score(a,labels)
                hom=homogeneity_score(a,labels)
                v=v_measure_score(a,labels)
                s=silhouette_score(data,a)
                d=davies_bouldin_score(data,a)
                c=calinski_harabasz_score(data,a)
                con=contingency_matrix(a,labels)
                cm=pair_confusion_matrix(a,labels)
                accuracy.append(acc)
                precision.append(p)
                recall.append(r)
                f1.append(f)
                rand.append(rands)
                adjusted_rand.append(ad_rands)
                mutual_info.append(mut)
                adjusted_mutual_info.append(ad_mut)
                fowlkes_mallows.append(fowlkes)
                homogeneity.append(hom)
                v_measure.append(v)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                contigencymatrix.append(con)
                confusion_matrix.append(cm)
                label.append(a)
            elif i=='agglomerative':
                mn=AgglomerativeClustering(n_clusters=clusters).fit_predict(data)
                acc=accuracy_score(mn,labels)
                p=precision_score(mn,labels,average='micro')
                r=recall_score(mn,labels,average='micro')
                f=f1_score(mn,labels,average='micro')
                rands=rand_score(mn,labels)
                ad_rands=adjusted_rand_score(mn,labels)
                mut=mutual_info_score(mn,labels)
                ad_mut=adjusted_mutual_info_score(mn,labels)
                fowlkes=fowlkes_mallows_score(mn,labels)
                hom=homogeneity_score(mn,labels)
                v=v_measure_score(mn,labels)
                s=silhouette_score(data,mn)
                d=davies_bouldin_score(data,mn)
                c=calinski_harabasz_score(data,mn)
                con=contingency_matrix(mn,labels)
                cm=pair_confusion_matrix(mn,labels)
                accuracy.append(acc)
                precision.append(p)
                recall.append(r)
                f1.append(f)
                rand.append(rands)
                adjusted_rand.append(ad_rands)
                mutual_info.append(mut)
                adjusted_mutual_info.append(ad_mut)
                fowlkes_mallows.append(fowlkes)
                homogeneity.append(hom)
                v_measure.append(v)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                contigencymatrix.append(con)
                confusion_matrix.append(cm)
                label.append(mn)
            elif i=='agglomerative-single':
                mn=AgglomerativeClustering(n_clusters=clusters,linkage='single').fit_predict(data)
                acc=accuracy_score(mn,labels)
                p=precision_score(mn,labels,average='micro')
                r=recall_score(mn,labels,average='micro')
                f=f1_score(mn,labels,average='micro')
                rands=rand_score(mn,labels)
                ad_rands=adjusted_rand_score(mn,labels)
                mut=mutual_info_score(mn,labels)
                ad_mut=adjusted_mutual_info_score(mn,labels)
                fowlkes=fowlkes_mallows_score(mn,labels)
                hom=homogeneity_score(mn,labels)
                v=v_measure_score(mn,labels)
                s=silhouette_score(data,mn)
                d=davies_bouldin_score(data,mn)
                c=calinski_harabasz_score(data,mn)
                con=contingency_matrix(mn,labels)
                cm=pair_confusion_matrix(mn,labels)
                accuracy.append(acc)
                precision.append(p)
                recall.append(r)
                f1.append(f)
                rand.append(rands)
                adjusted_rand.append(ad_rands)
                mutual_info.append(mut)
                adjusted_mutual_info.append(ad_mut)
                fowlkes_mallows.append(fowlkes)
                homogeneity.append(hom)
                v_measure.append(v)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                contigencymatrix.append(con)
                confusion_matrix.append(cm)
                label.append(mn)
            elif i=='agglomerative-complete':
                mn=AgglomerativeClustering(n_clusters=clusters,linkage='complete').fit_predict(data)
                acc=accuracy_score(mn,labels)
                p=precision_score(mn,labels,average='micro')
                r=recall_score(mn,labels,average='micro')
                f=f1_score(mn,labels,average='micro')
                rands=rand_score(mn,labels)
                ad_rands=adjusted_rand_score(mn,labels)
                mut=mutual_info_score(mn,labels)
                ad_mut=adjusted_mutual_info_score(mn,labels)
                fowlkes=fowlkes_mallows_score(mn,labels)
                hom=homogeneity_score(mn,labels)
                v=v_measure_score(mn,labels)
                s=silhouette_score(data,mn)
                d=davies_bouldin_score(data,mn)
                c=calinski_harabasz_score(data,mn)
                con=contingency_matrix(mn,labels)
                cm=pair_confusion_matrix(mn,labels)
                accuracy.append(acc)
                precision.append(p)
                recall.append(r)
                f1.append(f)
                rand.append(rands)
                adjusted_rand.append(ad_rands)
                mutual_info.append(mut)
                adjusted_mutual_info.append(ad_mut)
                fowlkes_mallows.append(fowlkes)
                homogeneity.append(hom)
                v_measure.append(v)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                contigencymatrix.append(con)
                confusion_matrix.append(cm)
                label.append(mn)
            elif i=='agglomerative-average':
                mn=AgglomerativeClustering(n_clusters=clusters,linkage='average').fit_predict(data)
                acc=accuracy_score(mn,labels)
                p=precision_score(mn,labels,average='micro')
                r=recall_score(mn,labels,average='micro')
                f=f1_score(mn,labels,average='micro')
                rands=rand_score(mn,labels)
                ad_rands=adjusted_rand_score(mn,labels)
                mut=mutual_info_score(mn,labels)
                ad_mut=adjusted_mutual_info_score(mn,labels)
                fowlkes=fowlkes_mallows_score(mn,labels)
                hom=homogeneity_score(mn,labels)
                v=v_measure_score(mn,labels)
                s=silhouette_score(data,mn)
                d=davies_bouldin_score(data,mn)
                c=calinski_harabasz_score(data,mn)
                con=contingency_matrix(mn,labels)
                cm=pair_confusion_matrix(mn,labels)
                accuracy.append(acc)
                precision.append(p)
                recall.append(r)
                f1.append(f)
                rand.append(rands)
                adjusted_rand.append(ad_rands)
                mutual_info.append(mut)
                adjusted_mutual_info.append(ad_mut)
                fowlkes_mallows.append(fowlkes)
                homogeneity.append(hom)
                v_measure.append(v)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                contigencymatrix.append(con)
                confusion_matrix.append(cm)
                label.append(mn)
            elif i=='birch-0.05':
                m=Birch(n_clusters=clusters,threshold=0.05)
                m.fit(data)
                a=m.labels_
                acc=accuracy_score(a,labels)
                p=precision_score(a,labels,average='micro')
                r=recall_score(a,labels,average='micro')
                f=f1_score(a,labels,average='micro')
                rands=rand_score(a,labels)
                ad_rands=adjusted_rand_score(a,labels)
                mut=mutual_info_score(a,labels)
                ad_mut=adjusted_mutual_info_score(a,labels)
                fowlkes=fowlkes_mallows_score(a,labels)
                hom=homogeneity_score(a,labels)
                v=v_measure_score(a,labels)
                s=silhouette_score(data,a)
                d=davies_bouldin_score(data,a)
                c=calinski_harabasz_score(data,a)
                con=contingency_matrix(a,labels)
                cm=pair_confusion_matrix(a,labels)
                accuracy.append(acc)
                precision.append(p)
                recall.append(r)
                f1.append(f)
                rand.append(rands)
                adjusted_rand.append(ad_rands)
                mutual_info.append(mut)
                adjusted_mutual_info.append(ad_mut)
                fowlkes_mallows.append(fowlkes)
                homogeneity.append(hom)
                v_measure.append(v)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                contigencymatrix.append(con)
                confusion_matrix.append(cm)
                label.append(a)
            elif i=='birch-0.1':
                m=Birch(n_clusters=clusters,threshold=0.05)
                m.fit(data)
                a=m.labels_
                acc=accuracy_score(a,labels)
                p=precision_score(a,labels,average='micro')
                r=recall_score(a,labels,average='micro')
                f=f1_score(a,labels,average='micro')
                rands=rand_score(a,labels)
                ad_rands=adjusted_rand_score(a,labels)
                mut=mutual_info_score(a,labels)
                ad_mut=adjusted_mutual_info_score(a,labels)
                fowlkes=fowlkes_mallows_score(a,labels)
                hom=homogeneity_score(a,labels)
                v=v_measure_score(a,labels)
                s=silhouette_score(data,a)
                d=davies_bouldin_score(data,a)
                c=calinski_harabasz_score(data,a)
                con=contingency_matrix(a,labels)
                cm=pair_confusion_matrix(a,labels)
                accuracy.append(acc)
                precision.append(p)
                recall.append(r)
                f1.append(f)
                rand.append(rands)
                adjusted_rand.append(ad_rands)
                mutual_info.append(mut)
                adjusted_mutual_info.append(ad_mut)
                fowlkes_mallows.append(fowlkes)
                homogeneity.append(hom)
                v_measure.append(v)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                contigencymatrix.append(con)
                confusion_matrix.append(cm)
                label.append(a)
            elif i=='birch-0.5':
                m=Birch(n_clusters=clusters,threshold=0.05)
                m.fit(data)
                a=m.labels_
                acc=accuracy_score(a,labels)
                p=precision_score(a,labels,average='micro')
                r=recall_score(a,labels,average='micro')
                f=f1_score(a,labels,average='micro')
                rands=rand_score(a,labels)
                ad_rands=adjusted_rand_score(a,labels)
                mut=mutual_info_score(a,labels)
                ad_mut=adjusted_mutual_info_score(a,labels)
                fowlkes=fowlkes_mallows_score(a,labels)
                hom=homogeneity_score(a,labels)
                v=v_measure_score(a,labels)
                s=silhouette_score(data,a)
                d=davies_bouldin_score(data,a)
                c=calinski_harabasz_score(data,a)
                con=contingency_matrix(a,labels)
                cm=pair_confusion_matrix(a,labels)
                accuracy.append(acc)
                precision.append(p)
                recall.append(r)
                f1.append(f)
                rand.append(rands)
                adjusted_rand.append(ad_rands)
                mutual_info.append(mut)
                adjusted_mutual_info.append(ad_mut)
                fowlkes_mallows.append(fowlkes)
                homogeneity.append(hom)
                v_measure.append(v)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                contigencymatrix.append(con)
                confusion_matrix.append(cm)
                label.append(a)
            elif i=='spectral':
                m=SpectralClustering(n_clusters=clusters)
                m.fit(data)
                a=m.labels_
                acc=accuracy_score(a,labels)
                p=precision_score(a,labels,average='micro')
                r=recall_score(a,labels,average='micro')
                f=f1_score(a,labels,average='micro')
                rands=rand_score(a,labels)
                ad_rands=adjusted_rand_score(a,labels)
                mut=mutual_info_score(a,labels)
                ad_mut=adjusted_mutual_info_score(a,labels)
                fowlkes=fowlkes_mallows_score(a,labels)
                hom=homogeneity_score(a,labels)
                v=v_measure_score(a,labels)
                s=silhouette_score(data,a)
                d=davies_bouldin_score(data,a)
                c=calinski_harabasz_score(data,a)
                con=contingency_matrix(a,labels)
                cm=pair_confusion_matrix(a,labels)
                accuracy.append(acc)
                precision.append(p)
                recall.append(r)
                f1.append(f)
                rand.append(rands)
                adjusted_rand.append(ad_rands)
                mutual_info.append(mut)
                adjusted_mutual_info.append(ad_mut)
                fowlkes_mallows.append(fowlkes)
                homogeneity.append(hom)
                v_measure.append(v)
                silhouette.append(s)
                davies.append(d)
                calinski.append(c)
                contigencymatrix.append(con)
                confusion_matrix.append(cm)
                label.append(a)
        dat['accuracy']=accuracy
        dat['precision']=precision
        dat['recall']=recall
        dat['f1']=f1
        dat['rand']=rand
        dat['adjusted rand']-adjusted_rand
        dat['mutual info']=mutual_info
        dat['adjusted mutual']=adjusted_mutual_info
        dat['fowlkes mallows']=fowlkes_mallows
        dat['homogeneity']=homogeneity
        dat['v measure']=v_measure
        dat['silhouette']=silhouette
        dat['davies-bouldin']=davies
        dat['calinski-harabasz']=calinski
        dat['contigency matrix']=contigencymatrix
        dat['confusion matrix']=confusion_matrix
        dat['labels']=label
        dat=dat.sort_values(by=['silhouette'])
        return dat
def plot_scatter_plot(data,dat):
    data=np.array(data)
    for i,j in zip(dat['labels'],dat['model']):
        plt.figure(figsize=(22,22))
        b=1
        plt.subplot(4,4,b)
        plt.scatter(data[:,0],data[:,1],c=i,s=50,cmap='viridis')
        plt.title(j)
        b=b+1
def get_metric_plot_classification(dat,metric):
                plt.figure(figsize=(10,10))
                return sns.barplot(data=dat,x=str(metric),y='model')
def plot_contingency_matrix(dat):
    bb=dat.loc[:,['contigency matrix']]
    for i,j in zip(range(len(dat['contigency matrix'])),dat['model']):
                        plt.figure(figsize=(22,22))
                        b=1
                        plt.subplot(4,4,b)
                        sns.heatmap(bb['contigency matrix'].loc[i],annot=True)
                        plt.title(j)
                        b=b+1
def plot_confusion_matrix(dat):
    for i,j in zip(dat['confusion matrix'],dat['model']):
                        a=len(dat['confusion matrix'])
                        plt.figure(figsize=(22,22))
                        b=1
                        plt.subplot(7,2,b)
                        sns.heatmap(i,annot=True)
                        plt.title(j)
                        b=b+1
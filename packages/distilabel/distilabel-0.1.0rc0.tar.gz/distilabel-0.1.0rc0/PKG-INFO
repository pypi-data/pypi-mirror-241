Metadata-Version: 2.1
Name: distilabel
Version: 0.1.0rc0
Summary: Automatic build of preference datasets for LLM alignment
Project-URL: Documentation, https://github.com/argilla/distilabel#readme
Project-URL: Issues, https://github.com/argilla/distilabel/issues
Project-URL: Source, https://github.com/argilla/distilabel
Author-email: Argilla <admin@argilla.io>
License-Expression: MIT
License-File: LICENSE
Keywords: alignment,annotation,llm
Classifier: Development Status :: 4 - Beta
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: Implementation :: CPython
Classifier: Programming Language :: Python :: Implementation :: PyPy
Requires-Python: >=3.8
Requires-Dist: datasets>=2.14.0
Requires-Dist: jinja2>=3.1.2
Provides-Extra: argilla
Requires-Dist: argilla>=1.16.0; extra == 'argilla'
Provides-Extra: dev
Requires-Dist: black==23.10.0; extra == 'dev'
Requires-Dist: pre-commit>=3.5.0; extra == 'dev'
Requires-Dist: ruff==0.1.0; extra == 'dev'
Provides-Extra: hf-inference-endpoints
Requires-Dist: huggingface-hub>=1.19.0; extra == 'hf-inference-endpoints'
Requires-Dist: tenacity>=8; extra == 'hf-inference-endpoints'
Provides-Extra: hf-transformers
Requires-Dist: torch>=2.0.0; extra == 'hf-transformers'
Requires-Dist: transformers>=4.34.1; extra == 'hf-transformers'
Provides-Extra: openai
Requires-Dist: openai>=1.0.0; extra == 'openai'
Provides-Extra: tests
Requires-Dist: pytest>=7.4.0; extra == 'tests'
Provides-Extra: vllm
Requires-Dist: vllm>=0.2.1; extra == 'vllm'
Description-Content-Type: text/markdown

 <div align="center">
   <h1>⚗️ distilabel</h1>
   <p>
     <em>AI feedback framework</em>
   </p>
 </div>

## What's distilabel
distilabel is a framework for building datasets with AI for LLM fine-tuning, evaluation, and alignment. 

It gives an extensible and scalable framework for AI Feedback (AIF) and model distillation, building on state of the art approaches such as UltraFeedback or JudgeLM.



{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch geometric algebra attention networks\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/klarh/geometric_algebra_attention/blob/master/examples/Basic%20structure%20tasks%20with%20pytorch.ipynb)\n",
    "\n",
    "This notebook formulates some deep learning layers using geometric algebra attention mechanisms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "# Colab-specific setup that will be ignored elsewhere\n",
    "if [ ! -z \"$COLAB_GPU\" ]; then\n",
    "    pip install plato-draw\n",
    "    pip install git+https://github.com/klarh/geometric_algebra_attention\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example pytorch networks using these layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as pt\n",
    "import geometric_algebra_attention.pytorch as gala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAANetClassifier(pt.nn.Module):\n",
    "    \"\"\"Create a classifier for neighborhoods.\n",
    "\n",
    "    Stacks permutation-covariant layers, then adds a permutation-invariant layer.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, D_in, num_classes, D=32, depth=2, dilation=2., residual=True,\n",
    "                 nonlinearities=True, merge_fun='mean', join_fun='mean', rank=2, dropout=0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.D_in = D_in\n",
    "        self.num_classes = num_classes\n",
    "        self.D = D\n",
    "        self.depth = depth\n",
    "        self.dilation = dilation\n",
    "        self.residual = residual\n",
    "        self.nonlinearities = nonlinearities\n",
    "        self.rank = rank\n",
    "        self.dropout = dropout\n",
    "        self.GAANet_kwargs = dict(merge_fun=merge_fun, join_fun=join_fun)\n",
    "\n",
    "        self.up_project = pt.nn.Linear(D_in, self.D)\n",
    "        self.class_project = pt.nn.Linear(self.D, self.num_classes)\n",
    "\n",
    "        self.make_attention_nets()\n",
    "\n",
    "        self.nonlin_mlps = []\n",
    "        if self.nonlinearities:\n",
    "            self.nonlin_mlps = pt.nn.ModuleList([self.make_value_net(self.D) for _ in range(self.depth + 1)])\n",
    "\n",
    "    def make_attention_nets(self):\n",
    "        D_in = lambda i: 1 if (i == self.depth and self.rank == 1) else 2\n",
    "        self.score_nets = pt.nn.ModuleList([self.make_score_net() for _ in range(self.depth + 1)])\n",
    "        self.value_nets = pt.nn.ModuleList([self.make_value_net(D_in(i)) for i in range(self.depth + 1)])\n",
    "\n",
    "        att_nets = []\n",
    "        for (scnet, vnet) in zip(self.score_nets, self.value_nets):\n",
    "            reduce = scnet is self.score_nets[-1]\n",
    "            rank = max(2, self.rank) if not reduce else self.rank\n",
    "            att_nets.append(gala.VectorAttention(self.D, scnet, vnet, reduce=reduce, rank=rank, **self.GAANet_kwargs))\n",
    "        self.att_nets = pt.nn.ModuleList(att_nets)\n",
    "\n",
    "    def make_score_net(self):\n",
    "        big_D = int(self.D*self.dilation)\n",
    "        layers = [\n",
    "            pt.nn.Linear(self.D, big_D),\n",
    "        ]\n",
    "\n",
    "        if self.dropout:\n",
    "            layers.append(pt.nn.Dropout(self.dropout))\n",
    "\n",
    "        layers.extend([\n",
    "            pt.nn.ReLU(),\n",
    "            pt.nn.Linear(big_D, 1),\n",
    "        ])\n",
    "        return pt.nn.Sequential(*layers)\n",
    "\n",
    "    def make_value_net(self, D_in, D_out=None):\n",
    "        D_out = D_out or self.D\n",
    "        big_D = int(self.D*self.dilation)\n",
    "        layers = [\n",
    "            pt.nn.Linear(D_in, big_D),\n",
    "            pt.nn.LayerNorm(big_D),\n",
    "        ]\n",
    "        if self.dropout:\n",
    "            layers.append(pt.nn.Dropout(self.dropout))\n",
    "\n",
    "        layers.extend([\n",
    "            pt.nn.ReLU(),\n",
    "            pt.nn.Linear(big_D, D_out),\n",
    "        ])\n",
    "        return pt.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        (r, v) = x\n",
    "\n",
    "        last = self.up_project(v)\n",
    "\n",
    "        for i, attnet in enumerate(self.att_nets):\n",
    "            residual = last\n",
    "            last = attnet((r, last))\n",
    "            if self.nonlinearities:\n",
    "                last = self.nonlin_mlps[i](last)\n",
    "            if self.residual and attnet is not self.att_nets[-1]:\n",
    "                last = last + residual\n",
    "\n",
    "        last = self.class_project(last)\n",
    "        last = pt.nn.Softmax(-1)(last)\n",
    "\n",
    "        return last\n",
    "\n",
    "class GAANetVectorRegressor(GAANetClassifier):\n",
    "    \"\"\"Learn a model to regress a (geometric) vector from inputs.\n",
    "\n",
    "    Stacks permutation-invariant layers that manipulate the values stored\n",
    "    at each vertex, then adds a permutation-invariant, rotation-covariant layer on top.\n",
    "\n",
    "    \"\"\"\n",
    "    def make_attention_nets(self):\n",
    "        D_in = lambda i: 1 if (i == self.depth and self.rank == 1) else 2\n",
    "        self.score_nets = pt.nn.ModuleList([self.make_score_net() for _ in range(self.depth + 1)])\n",
    "        self.value_nets = pt.nn.ModuleList([self.make_value_net(D_in(i)) for i in range(self.depth + 1)])\n",
    "\n",
    "        self.final_scale_net = self.make_value_net(self.D, 1)\n",
    "\n",
    "        att_nets = []\n",
    "        for (scnet, vnet) in zip(self.score_nets, self.value_nets[:-1]):\n",
    "            rank = max(self.rank, 2)\n",
    "            att_nets.append(gala.VectorAttention(self.D, scnet, vnet, reduce=False, rank=rank, **self.GAANet_kwargs))\n",
    "        att_nets.append(gala.Vector2VectorAttention(\n",
    "            self.D, self.score_nets[-1], self.value_nets[-1], self.final_scale_net, reduce=True, rank=self.rank, **self.GAANet_kwargs))\n",
    "        self.att_nets = pt.nn.ModuleList(att_nets)\n",
    "\n",
    "    @property\n",
    "    def class_project(self):\n",
    "        return None\n",
    "\n",
    "    @class_project.setter\n",
    "    def class_project(self, value):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        (r, v) = x\n",
    "\n",
    "        last = self.up_project(v)\n",
    "\n",
    "        for i, attnet in enumerate(self.att_nets):\n",
    "            residual = last\n",
    "            last = attnet((r, last))\n",
    "            if self.nonlinearities and attnet is not self.att_nets[-1]:\n",
    "                last = self.nonlin_mlps[i](last)\n",
    "            if self.residual and attnet is not self.att_nets[-1]:\n",
    "                last = last + residual\n",
    "\n",
    "        return last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# nearest neighbors for NaCl structure type (simple cubic grid with alternating particle types)\n",
    "pos = np.array(list(itertools.product(*(3*[[-1, 0, 1]]))))\n",
    "# remove center (its type would be 0)\n",
    "pos = pos[np.any(pos != 0, axis=-1)]\n",
    "\n",
    "# particle types\n",
    "types = (np.sum(pos, axis=-1)%2).astype(np.int32)\n",
    "max_types = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell just performs a very simple visualization, don't worry if you don't have plato installed\n",
    "import plato, plato.imp as imp\n",
    "\n",
    "imp.spheres(positions=pos, colors=plato.cmap.cubehelix(.3 + .4*types.astype(np.float32)))\n",
    "imp.show(backend='zdog', zoom=8, features=dict(ambient_light=.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Identify warped neighborhoods (rotation invariant)\n",
    "\n",
    "This task randomly squishes neighborhoods in 3 directions and learns to distinguish between neighborhoods that just have random noise added to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_types(ti, tj, max_types):\n",
    "    ti_onehot = np.eye(max_types)[ti]\n",
    "    tj_onehot = np.eye(max_types)[tj]\n",
    "    return np.concatenate([ti_onehot - tj_onehot, ti_onehot + tj_onehot], axis=-1)\n",
    "\n",
    "xs, ts, ys = [], [], []\n",
    "for _ in range(512):\n",
    "    x = pos.astype(np.float32)\n",
    "    x += np.random.normal(scale=5e-2)\n",
    "    ti = 0\n",
    "    tj = types.copy()\n",
    "    y = 0 # unsquished\n",
    "\n",
    "    if np.random.rand() < .5:\n",
    "        ti = 1 - ti\n",
    "        tj = 1 - tj\n",
    "\n",
    "    if np.random.rand() < .5:\n",
    "        squish = np.random.normal(1, .25, 3)\n",
    "        x*= squish\n",
    "        y = 1\n",
    "\n",
    "    xs.append(x)\n",
    "    ts.append(encode_types([ti], tj, max_types))\n",
    "    ys.append(y)\n",
    "\n",
    "xs = np.array(xs)\n",
    "ts = np.array(ts)\n",
    "ys = np.array(ys)\n",
    "\n",
    "xs = pt.tensor(xs, dtype=pt.get_default_dtype())\n",
    "ts = pt.tensor(ts, dtype=pt.get_default_dtype())\n",
    "ys = pt.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "model = GAANetClassifier(ts.shape[-1], 2, 16, depth=2, rank=1,\n",
    "                         merge_fun='mean', join_fun='mean', dropout=0.5)\n",
    "optim = pt.optim.Adam(model.parameters())\n",
    "batches = np.arange(0, len(xs), batch_size)\n",
    "train_batches, val_batches = batches[len(batches)//4:], batches[:len(batches)//4]\n",
    "\n",
    "def loop(batches, train=True):\n",
    "    np.random.shuffle(batches)\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    stats = []\n",
    "    for batch_start in batches:\n",
    "        batch = slice(batch_start, batch_start + batch_size)\n",
    "        pred = model((xs[batch], ts[batch]))\n",
    "        loss = pt.nn.CrossEntropyLoss()(pred, ys[batch])\n",
    "\n",
    "        if train:\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "        acc = pred.argmax(-1).eq(ys[batch]).double().mean(dim=0).item()\n",
    "        stats.append((loss.detach().numpy(), acc))\n",
    "    return stats\n",
    "\n",
    "for epoch in range(32):\n",
    "    stats = loop(train_batches)\n",
    "    print('train loss, accuracy', *np.mean(stats, axis=0))\n",
    "    stats = loop(val_batches, False)\n",
    "    print('val loss, accuracy', *np.mean(stats, axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Fill in the blanks (rotation covariant)\n",
    "\n",
    "This network learns to produce a vector which has been randomly deleted from the input set of neighboring points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ts, ys = [], [], []\n",
    "for _ in range(512):\n",
    "    x = pos.astype(np.float32)\n",
    "    x += np.random.normal(scale=5e-2)\n",
    "    ti = 0\n",
    "    tj = types.copy()\n",
    "    index_to_take = np.random.randint(0, pos.shape[0] - 1)\n",
    "\n",
    "    if np.random.rand() < .5:\n",
    "        ti = 1 - ti\n",
    "        tj = 1 - tj\n",
    "\n",
    "    y = x[index_to_take].copy()\n",
    "    x = np.concatenate([x[:index_to_take], x[index_to_take + 1:]], axis=0)\n",
    "    t = encode_types([ti], tj, max_types)\n",
    "    t = np.concatenate([t[:index_to_take], t[index_to_take + 1:]], axis=0)\n",
    "\n",
    "    xs.append(x)\n",
    "    ts.append(t)\n",
    "    ys.append(y)\n",
    "\n",
    "xs = np.array(xs)\n",
    "ts = np.array(ts)\n",
    "ys = np.array(ys)\n",
    "\n",
    "xs = pt.tensor(xs, dtype=pt.get_default_dtype())\n",
    "ts = pt.tensor(ts, dtype=pt.get_default_dtype())\n",
    "ys = pt.tensor(ys, dtype=pt.get_default_dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "model = GAANetVectorRegressor(\n",
    "    ts.shape[-1], 2, 32, depth=2, rank=1,\n",
    "    merge_fun='mean', join_fun='mean')\n",
    "optim = pt.optim.Adam(model.parameters())\n",
    "batches = np.arange(0, len(xs), batch_size)\n",
    "train_batches, val_batches = batches[len(batches)//4:], batches[:len(batches)//4]\n",
    "\n",
    "def loop(batches, train=True):\n",
    "    np.random.shuffle(batches)\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    stats = []\n",
    "    for batch_start in batches:\n",
    "        batch = slice(batch_start, batch_start + batch_size)\n",
    "        pred = model((xs[batch], ts[batch]))\n",
    "        loss = pt.nn.MSELoss()(pred, ys[batch])\n",
    "\n",
    "        if train:\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "        stats.append((loss.detach().numpy()))\n",
    "    return stats\n",
    "\n",
    "for epoch in range(16):\n",
    "    stats = loop(train_batches)\n",
    "    print('train', np.mean(stats, axis=0))\n",
    "    stats = loop(val_batches, False)\n",
    "    print('val', np.mean(stats, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Basic structure tasks with pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

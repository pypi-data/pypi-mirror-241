{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "522fcbb3-702c-4ea0-91d9-f3b0e71690fc",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰àᦴ΀࣪ʐ怶䦠挠᱊ࠥ䁁䂖㚥煤晬փ⊪ĸ暂䙠঳ैkᑄᄈ妐ଷᓋ⃩䖻Ṯ溜Φ䐡傠Ǒ団Қ′䈤7ࡣᠠ湐戎Ⴆ寐爤䀥屨攠ʕ㥀ǔÚ䍃㏙䤥ࢂ┩勸惀Ēいཆ༠೥∁∀秸㲅䌠ⶬᛦ䙂ǃɡ殍戰泤ᒁ嬦怭㋉匥穃ᄠ彣჻⴦䉫ぢ睤䄁ⵐۻG䀡曑砑䂱竖ᄂ㜿Ꭽ˹ȩᚱ凁兘㑐Ṣ༩Ẻ䳥⑆憰棨忞⍧攈堽Ī僰὆揖䦲ᡊ⛓౱নఱ姼ᤦΧ您別൧儸晋Ǣ熘繀䉁硨K塊়ṹᜰ倳䪂ⵦ⚈ᒽ᪺ᆬ䀠 "
   },
   "source": [
    "# Analyzing Utah Avalanche Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e689b2cd-d64d-428b-8a33-e120a87fb0ce",
   "metadata": {},
   "source": [
    "**Participant ID:**  \n",
    "**Date / Time:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceac0d48-2820-4532-bfd2-adf6533d7a2d",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Welcome to our data analysis study. For this part of the study, you'll be working with a dataset sourced from the [Utah Avalanche Center](https://utahavalanchecenter.org/). The data provides insights into [avalanche occurrences](https://utahavalanchecenter.org/avalanches) in Utah."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2e1070-396c-412c-b81c-767605d7be23",
   "metadata": {},
   "source": [
    "#### Persist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68491102-96aa-4701-8134-d998c80ae04b",
   "metadata": {},
   "source": [
    "- The PersIst extension is already installed and enabled in this notebook.\n",
    "- To familiarize yourself with its functionalities, please refer to the provided [tutorial notebook](../tutorial.ipynb).\n",
    "- Interactive charts and tables have been pre-created for your convenience. These can be directly utilized by running the corresponding cells.\n",
    "- Focus on leveraging the interactive capabilities of Persist for your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905153f6-39fd-4fa8-8eae-fa4818de0df6",
   "metadata": {},
   "source": [
    "#### Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4c85d1-1882-4b59-9cc3-26dc6b1e358d",
   "metadata": {},
   "source": [
    "- Pandas is set up and ready for use, along with other Python libraries such as Matplotlib, Seaborn, and Altair for data visualization.\n",
    "- You are allowed to use internet resources like documentation and forums, including Stack Overflow, to assist you in completing the tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b5d524-883a-460b-8023-2c6aab29570f",
   "metadata": {},
   "source": [
    "## Tasks Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebadbe2-4497-401c-9220-017809e835de",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ૠବɐච䎍倶䊪ᠠ父嬡ᳺ෪ੲࠬ晴ᘦ㍲差Ⱗㅅ)㊤䈽ାƂ刴喋橖㎁混䩟ႠᨰV岸㈔␢⡠䀢焧匠෦భ戰௷㙠̸x䠊䀡᲼䠠洠⺾彡抄䀠㈉㶣㡶ᡈ\\䰩(懄燃㌂㰢ᒌ娾䀶挥㗦ࢢ烡ၕ⬱жㄢ៉䓐͸⮑ŝㄐ䁏你㋲既祸ၛᅀ㢆䰽⫠਀⻚粀幝ඨ࣓叾殪㙡ƨ◓ᰢ寘奇Ⴌ䦦糂礒৉ᱥ䩃༥ס扦᤭ԓ噻ҩᆠ剋࣡ସ䂡▥撰じ㸨䅃䢴മ䂁ᣌ㬫䈁碢➫怢崢悩欂䥑央Ⴧ掴≺䩬槔ဨ搠 "
   },
   "source": [
    "In this study, you are presented with three fundamental data analysis tasks. Each task is designed to test different aspects of data analysis and manipulation.\n",
    "\n",
    "- Carefully follow the step-by-step instructions provided for each task.\n",
    "- As you work through the tasks, take note of any interesting findings or challenges you encounter.\n",
    "- Feel free to add new code and markdown cells in the notebook as necessary to complete the tasks.\n",
    "- Document your findings and any challenges faced during the analysis in markdown cells. This can include observations about the data, any issues encountered, and your overall experience with the task/method.\n",
    "\n",
    "**Support**\n",
    "- If you require assistance or need further clarification on any of the tasks, please let us know.\n",
    "- If you find yourself stuck on a task and feel that you will not make any progress, you have the option to skip the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9337796b-21e8-4c8c-bbbd-3076a775d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "import persist_ext as PR\n",
    "\n",
    "PR.dev.Dev = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd81aecd-eebf-4624-b9e2-3a864c474c1d",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰Ҁ̡䘠烠嘢త〫‥侴ᓬᛞ拐ৡ䚂ద抭婈ހڅྯ䌲⠠䭈⑁槑焳Ⴥ⩦仃㍶๽㰥Ҩǁ#㟢䌰橠ኤРᜰ͐üメ湁˛㾄ָ̠憴)挄䀦栢琭ٮ㍄ᨡ䌤ᾣㆢ䀣擠䢤㘦Sᥧᡠ戂怡ᠬÖᠻ㹈䐿ة׉妨⃓ࢱ̴㖠᫲徤ฏѤƜڣ回㸦ۡ৵ण䃔戊㘠传ϊ緯挡䘌污䕽庮粓㈨ɪⷠ搃猄ᦨ洘㳌ᤪ̪౦繶ሱ澂䘣⁑Ҝഭ炍孉ृÅ⭱䤾ᢠ䆋෭ኀ㠢Ү≱呺Ấ惑汮ᮯ戩䊏̠˙Ɂ⧽憳㈒ṉⅱਊ⥋⃆瑀⣨  "
   },
   "source": [
    "## Data Description\n",
    "\n",
    "The table below describes the different columns in the dataset. Each row in the dataset represents a reported avalanche with details on location, trigger, and aspect. The data spans multiple years, starting from 2004 up to 2023.\n",
    "\n",
    "| Column          | Description                                                    |\n",
    "|-----------------|----------------------------------------------------------------|\n",
    "| Date            | Date on which the avalanche was recorded                       |\n",
    "| Region          | Region in Utah where the avalanche occurred                    |\n",
    "| Place           | Exact location where the avalanche was recorded                |\n",
    "| Trigger         | Cause of the avalanche                                         |\n",
    "| Weak Layer      | Layer of snow that was weakest and likely to fail              |\n",
    "| Depth_inches    | Depth of the avalanche in inches                               |\n",
    "| Width_inches    | Width of the avalanche in inches                               |\n",
    "| Vertical_inches | Vertical distance covered by the avalanche in inches           |\n",
    "| Aspect          | Direction of the slope where the avalanche occurred            |\n",
    "| Elevation_feet  | Elevation of the location in feet                              |\n",
    "| Coordinates     | Approximate geographical coordinates of the avalanche location |\n",
    "| Comments 1      | Additional comments provided by the reporter                   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0e426c-89a0-4813-8994-65ebba3f3a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>;Region</th>\n",
       "      <th>Place</th>\n",
       "      <th>;Trigger</th>\n",
       "      <th>;Weak Layer</th>\n",
       "      <th>Depth_inches</th>\n",
       "      <th>Width_inches</th>\n",
       "      <th>Vertical_inches</th>\n",
       "      <th>;Aspect</th>\n",
       "      <th>Elevation_feet</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>Comments 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/9/2012</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>Sunset Peak</td>\n",
       "      <td>Snowboarder</td>\n",
       "      <td>New Snow/Old Snow Interface</td>\n",
       "      <td>14.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>North</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>40.577977000000, -111.595817000000</td>\n",
       "      <td>While it was a small avalanche that was I caug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/11/2012</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>Patsy Marly</td>\n",
       "      <td>Skier</td>\n",
       "      <td>New Snow/Old Snow Interface</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>North</td>\n",
       "      <td>9700.0</td>\n",
       "      <td>40.592619000000, -111.616099000000</td>\n",
       "      <td>A North facing aspect with an exposed ridge in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/11/2012</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>Two Dogs</td>\n",
       "      <td>Skier</td>\n",
       "      <td>Facets</td>\n",
       "      <td>36.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>North</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>40.599291000000, -111.642315000000</td>\n",
       "      <td>Remotely triggered all the new storm snow (abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/11/2012</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>Emma Ridges</td>\n",
       "      <td>Skier</td>\n",
       "      <td>New Snow</td>\n",
       "      <td>18.0”</td>\n",
       "      <td>600.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>40.598313000000, -111.628304000000</td>\n",
       "      <td>Impressive fast powder cloud ran in front of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/11/2012</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>Sunset Peak</td>\n",
       "      <td>Skier</td>\n",
       "      <td>Facets</td>\n",
       "      <td>42.0</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>North</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>40.578590000000, -111.595087000000</td>\n",
       "      <td>Three of us toured from Brighton to low saddle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>4/22/2023</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>Cardiff Bowl</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>New Snow/Old Snow Interface</td>\n",
       "      <td>8.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>East</td>\n",
       "      <td>9800.0</td>\n",
       "      <td>40.592721660567, -111.649613218710</td>\n",
       "      <td>We spent the day skiing the southerly-facing a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>4/22/2023</td>\n",
       "      <td>Logan</td>\n",
       "      <td>Miller Bowl, East</td>\n",
       "      <td>Snowmobiler</td>\n",
       "      <td>New Snow/Old Snow Interface</td>\n",
       "      <td>18.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>North</td>\n",
       "      <td>8700.0</td>\n",
       "      <td>41.886233332343, -111.645074831510</td>\n",
       "      <td>Not sure about the story here, but we observed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>4/22/2023</td>\n",
       "      <td>Logan</td>\n",
       "      <td>Millville Peak</td>\n",
       "      <td>Snowboarder</td>\n",
       "      <td>New Snow/Old Snow Interface</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>North</td>\n",
       "      <td>8900.0</td>\n",
       "      <td>41.677564539953, -111.718065248970</td>\n",
       "      <td>Details are a bit limited and we're not sure w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>5/7/2023</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>Red Top Mountain</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>West</td>\n",
       "      <td>10800.0</td>\n",
       "      <td>40.546874131921, -111.663880335390</td>\n",
       "      <td>Saw this avalanche around 9.30 AM from the top...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>5/9/2023</td>\n",
       "      <td>Salt Lake</td>\n",
       "      <td>Microwave</td>\n",
       "      <td>Skier</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>6.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>West</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>40.589449603656, -111.613240229200</td>\n",
       "      <td>Intentionally triggered during a ski cut. Ran ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2392 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    ;Region              Place     ;Trigger  \\\n",
       "0      11/9/2012  Salt Lake        Sunset Peak  Snowboarder   \n",
       "1     11/11/2012  Salt Lake        Patsy Marly        Skier   \n",
       "2     11/11/2012  Salt Lake           Two Dogs        Skier   \n",
       "3     11/11/2012  Salt Lake        Emma Ridges        Skier   \n",
       "4     11/11/2012  Salt Lake        Sunset Peak        Skier   \n",
       "...          ...        ...                ...          ...   \n",
       "2387   4/22/2023  Salt Lake       Cardiff Bowl      Unknown   \n",
       "2388   4/22/2023      Logan  Miller Bowl, East  Snowmobiler   \n",
       "2389   4/22/2023      Logan     Millville Peak  Snowboarder   \n",
       "2390    5/7/2023  Salt Lake   Red Top Mountain      Natural   \n",
       "2391    5/9/2023  Salt Lake          Microwave        Skier   \n",
       "\n",
       "                      ;Weak Layer Depth_inches  Width_inches  Vertical_inches  \\\n",
       "0     New Snow/Old Snow Interface         14.0         960.0            360.0   \n",
       "1     New Snow/Old Snow Interface         30.0        1200.0           1200.0   \n",
       "2                          Facets         36.0         840.0           5400.0   \n",
       "3                        New Snow        18.0”         600.0           6000.0   \n",
       "4                          Facets         42.0       18000.0           9600.0   \n",
       "...                           ...          ...           ...              ...   \n",
       "2387  New Snow/Old Snow Interface          8.0         720.0           1800.0   \n",
       "2388  New Snow/Old Snow Interface         18.0         540.0           4800.0   \n",
       "2389  New Snow/Old Snow Interface         12.0        3600.0           7200.0   \n",
       "2390                      Unknown         72.0        3000.0          12000.0   \n",
       "2391                      Unknown          6.0         300.0           2400.0   \n",
       "\n",
       "        ;Aspect  Elevation_feet                         Coordinates  \\\n",
       "0         North         10400.0  40.577977000000, -111.595817000000   \n",
       "1         North          9700.0  40.592619000000, -111.616099000000   \n",
       "2         North         10200.0  40.599291000000, -111.642315000000   \n",
       "3     Southeast         10200.0  40.598313000000, -111.628304000000   \n",
       "4         North         10400.0  40.578590000000, -111.595087000000   \n",
       "...         ...             ...                                 ...   \n",
       "2387       East          9800.0  40.592721660567, -111.649613218710   \n",
       "2388      North          8700.0  41.886233332343, -111.645074831510   \n",
       "2389      North          8900.0  41.677564539953, -111.718065248970   \n",
       "2390       West         10800.0  40.546874131921, -111.663880335390   \n",
       "2391       West         10000.0  40.589449603656, -111.613240229200   \n",
       "\n",
       "                                             Comments 1  \n",
       "0     While it was a small avalanche that was I caug...  \n",
       "1     A North facing aspect with an exposed ridge in...  \n",
       "2     Remotely triggered all the new storm snow (abo...  \n",
       "3     Impressive fast powder cloud ran in front of t...  \n",
       "4     Three of us toured from Brighton to low saddle...  \n",
       "...                                                 ...  \n",
       "2387  We spent the day skiing the southerly-facing a...  \n",
       "2388  Not sure about the story here, but we observed...  \n",
       "2389  Details are a bit limited and we're not sure w...  \n",
       "2390  Saw this avalanche around 9.30 AM from the top...  \n",
       "2391  Intentionally triggered during a ski cut. Ran ...  \n",
       "\n",
       "[2392 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./avalanches_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc10d2b-9b1e-46f4-9769-b9a0ac0c9e8f",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ૠ㌬Ā჻R〶䁃lyٹ⁓f䍐ۢ䧪㈉◔ฅޡ䨲⠠䬱䑁棒瀱Ⴭ⭱妻ݎẜʤ䐡傠ǖ悃РኤРᜰ結üメ浪巟㈠ᣠˬ⃪$熒‣㐡㬚͇⦲༿⸂໡壡‡犀⒂ଠᎭॣ䥡⊃㡹稠嬸ූᑤඦҡ哹䑀妨䤝͕䀺慽䈩瞤∡㼚ƶ嵖᯦悡檩ǣ᪀畖o#䖊⠃ܑ璌⃥⹾䞌᧒Т⺈ᆡ⇳㴑䒤㒌ŭ᯸丈◡戱⃰潅Ԧ秐噑๦磜疶溂⒀ᒪ扖⋦ူⶃ㧄మྡྷშ⨭རㅸ瘭ǅ爘䅐䘆砠址䑂㥨㈼㹯䕈䓵ᒹ憴婊③ᤠ "
   },
   "source": [
    "# Task 1: Column Names and Data Types\n",
    "\n",
    "In the first task we will perform some basic data cleaning operations to get our dataset ready for further tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8934b219-dd97-4e3e-9aa9-0dd7a9d62ad5",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ૠ㬠氤〥䌸瀶䀹䁣๲ৠܦᔨҀᣴ䂼䋃‣ᓆ做►䀳ല⠠䭈⑁槑瀱ᝉ⍮冫㭮ẜʦ䒠ǁ#㕀挸晠ኤРᝣၐüムṁǟ㤉䀥䉸攠ʓ㥀ǔÚ⎃஥䤫䒄攭ᇸ惀Ēいᘦᖠೣ䗫⃂変ⱦ{ఽ咼∪⌤䋵汄ჹ䑈冣ᛠඉⵆܔ⍂Þ⍡歹ম悩溩Ǡ媁疖o#䖓瀃ʅ璌⁅溮杲◒Ъ⍁䔶户ࣉⓢ削౐䘰䵥䌂んḸئԢ灐糕൤㧶ⶬ䲱䅲ᗈ撯ౠ惍䈅䥐属ѣ၈⩍སヸ๗௧焤ᄸ䒰Ž䅰䔉燩壥༲刳樲⭮✈咰ᒄ  "
   },
   "source": [
    "### **Task 1a: Remove Columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b531d4-2e3a-4e9a-b92a-39aebfc3deb6",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ૠ㬠氤〥䌸瀶䀹䁣๲ৠܦᔨҀᣴ䂼䋃‣ᓆ做►䀳ല⠠䭈⑁槑瀱ᝉ⍮冫㭮ẜʦ䒠ǁ#㕀挸晠ኤРᝣၐüムṁǟ㤉䀥䉸攠ʓ㥀ǔÚ⎃஥䤫䒄攭ᇸ惀Ēいᘦᖠೣ䗫⃂変ⱦ{ఽ咼∪⌤䋵汄ჹ䑈冣ᛠඉⵆܔ⍂Þ⍡歹ম悩溩Ǡ媁疖o#䖓瀃ʅ璌⁅溮杲◒Ъ⍁䔶户ࣉⓢ削౐䘰䵥䌂んḸئԢ灐糕൤㧶ⶬ䲱䅲ᗈ撯ౠ惍䈅䥐属ѣ၈⩍སヸ๗௧焤ᄸ䒰Ž䅰䔉燩壥༲刳樲⭮✈咰ᒄ  "
   },
   "source": [
    "#### **Objective**\n",
    "Remove certain columns to streamline the dataset for further analysis.\n",
    "- **_Comments 1:_** Contains textual comments not crucial for quantitative analysis.\n",
    "- **_Coordinates:_** Detailed location data not needed for the current scope of analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32306297-3b43-4d46-8313-95f17822fea9",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ˣĸѐᦻϐրୣF☡䲩※ਡᱤĀၑ䀦ᆺⵕ暕ᣀɒ㉪2攩кᙼ䉅擊桖㎉淢域ᑡᅀ†浑ӦẰӁĠװ搬W౐ި₏湝〡㜶ᥠ¼湨N䣸持㉧ㄺ奣ᢖᡈ\\䰩ຣ⟆惂䧹夔琴Ī࣠ஃϔ憨䅐悰㫛㢤᭑Դ㈵堣ⳋᣡ㺨摠៨摖棄拑氰己ၘ⭬ǎ怩瀠㧎㸜ヌ㻍䑘己洉䓖₢◄㒜♶ᑚਨ䛤撁∴惘⡰ᑂཊ怰⾚ጥ΀䲌ᇩ复劄䘪䧌挴⊂̥㘯١䄁碂಩⍰瑦֡憐㱞lከ䤠ᗸᔩ亾ⲷࡰ৪ㅍ⍆㓺ᕟ⌹  "
   },
   "source": [
    "#### Persist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec9ad2a-ab09-4288-b8fa-2852bcddda1a",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Column Removal:**\n",
    "\t- Use the interactive table feature in PersIst to remove the specified columns.\n",
    "2. **Generate dataframe:**\n",
    "\t- Assign the modified dataframe to variable `df_task_1a`\n",
    "3. **Show Output:**\n",
    "\t- Print the head of `df_task_1a` to show the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41f55f22-f954-4a4e-ba42-f8b6da6f14a4",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "ᯡࠩ䃬࿀ᜤᠹ悋ᐨ掺‷ᒰ๮Öŭ宭Ẅ梊䐠㑀Ӑ 䁯⌸಍䘠✠垂Þ兠 ",
    "__has_persist_output": true,
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰۠ጠత煠瘵〶䁋Ԡ昢ᤨˠࣣㆤĀ寃ᖑ䱴Ĭᓡ⊣ز⠠䭈⑁槑瀱ᝅ❡始㭮溜ʤ䐡傠Ǒ痃′䈤7࢝ᠠ湐憎Ⴄ姗㈠ᣠˬ⃪$皒‣㐡㬚ͧ⦲̿⸂ਆ壡‡犀⑶َ⌭֫䍥ッ琡㙐款⢨ެथ⻓ࡡ㌱ሚ婋U䳇䐵漨䐢縔絭㈾㟕䄭唲Τ㒫ၡ嘠传β柷挭猏ⱡ䑼帮ṓ㋤䩥ʠڀ僾⧉҄ٺഽذ䭡⛁岱䦎澭恱熖⼺槒䢲ᠪ≂กᆨв奼楆Χ您剅ͧ儸ᘻࡠ烘幟ࡆࣜ漠଄ࢥ䝗١䟩壅༺刳䓭ಳ傠䍀  "
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a91e9d6a96445f48207a56248b09649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PersistWidget(data_values=[{'__id_column': '1', 'Date': 1352419200000, ';Region': 'Salt Lake', 'Place': 'Sunse…"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PR.PersistTable(df, df_name=\"df_task_1a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca08701b-2697-480f-8faf-681ce82a9aba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_task_1a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_task_1a\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_task_1a' is not defined"
     ]
    }
   ],
   "source": [
    "df_task_1a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563eb8ea-66c6-4c03-9c4c-54ea2eb717e1",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ˣĸѐᦻϐրୣF☡䲩※ਡᱤĀၑ䀦ᆺⵕ暕ᣀɒ㉪2攩кᙼ䉅擊桖㎉淢域ᑡᅀ†浑ӦẰӁĠװ搬W౐ި₏湝〡㜶ᥠ¼湨N䣸持㉧ㄺ奣ᢖᡈ\\䰩ຣ⟆惂䧹夔琴Ī࣠ஃϔ憨䅐悰㫛㢤᭑Դ㈵堣ⳋᣡ㺨摠៨摖棄拑氰己ၘ⭬ǎ怩瀠㧎㸜ヌ㻍䑘己洉䓖₢◄㒜♶ᑚਨ䛤撁∴惘⡰ᑂཊ怰⾚ጥ΀䲌ᇩ复劄䘪䧌挴⊂̥㘯١䄁碂಩⍰瑦֡憐㱞lከ䤠ᗸᔩ亾ⲷࡰ৪ㅍ⍆㓺ᕟ⌹  "
   },
   "source": [
    "#### Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4a5a56-a415-44d4-9be4-4c4e22f68502",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Column Removal:**\n",
    "\t- Remove the specified columns using Pandas commands.\n",
    "2. **Generate dataframe:**\n",
    "\t- Assign the modified dataframe to variable `df_task_1a`\n",
    "3. **Show Output:**\n",
    "\t- Print the head of `df_task_1a` to show the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b15449b-4ead-4e30-b779-dd88a7169454",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dc5ff1-bd9c-44fe-ab9f-454e3341195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1a = df.drop(columns=[\"Comments 1\", \"Coordinates\"])\n",
    "\n",
    "df_task_1a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c62d50-9c88-4ed9-8c97-e552a6e4c620",
   "metadata": {},
   "source": [
    "### **Task 1b: Fix Column Names**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8f8f24-afd2-424f-ab34-3e3cde723aa3",
   "metadata": {
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ࢀㆪこ<ǐʀ୥崡汤Ɓ䔠⍂⠨撂䂼ì债晶堪慯掩ᐠ▴ሰ璹㤨䮲减ⓥ䢧᜾㺣䉠ð䀡壅冨㕀ॢȠ௞䠸ᢀ眰䅽忖䀢晐樠Ԃ牠ΈƔڦ❓ሠƠ暬ॡ声Ȅ恨䙜⬮ಬ俨⫣䞐డ㙐᬴⣔䰲ճ㌰䊆၂۔欠㖹┰᧶༨̘ඛฌ琻ɋ㉄ܠ榡哸Ŝ.ؗ⾬ള勑̵㯺ᱱ曨ဩᒡᾪ३⁂惡৒ј⪖ᩋࢶ䥣䍢ᇃ⢀☾ԣ䖎㑝䳓ⳄⓀ᪱ĦҐ戤׌㝔䆦成扉ڠ凈㨣ೣㅘ湏Bࡤ䒠ଈତޗ٩䟨㣜㥨◈ᩲ㭡⟢䀠 "
   },
   "source": [
    "#### **Objective**\n",
    "For this subtask, we will focus on fixing column names to ensure consistency and clarity. We'll start by identifying the issues with the column names, specifically targeting those with a `;` prefix that needs removal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedcbe71-9d1d-4e28-a869-cb07b33f8074",
   "metadata": {},
   "source": [
    "#### Persist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f4d5c5-9383-4857-beae-0cfa6ba466f2",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Rename Columns:**\n",
    "    - Use the interactive  table in Persist to correct the column names by removing the leading `;` from their names:\n",
    "        - _;Aspect_ → _Aspect_\n",
    "        - _;Region_ → _Region_\n",
    "        - _;Trigger_ → _Trigger_\n",
    "        - _;Weak Layer_ → _Weak Layer_\n",
    "2. **Generate dataframe:**\n",
    "    - Assign the revised dataframe to the variable `df_task_1b`.\n",
    "3. **Show Output:**\n",
    "    - Display the head of `df_task_1b` to verify the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e74dd265-2437-40e4-8673-be7ea1d079b3",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "ᯡࠣ䅬Ԁ朤壠ᜣ琢〹夤゠⹰〮⁁䁻қ䚾ኊ㇠നСࠩ瀮晼Ƭ穅5愠៤⠠ ",
    "__has_persist_output": true,
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ǣƬԀච☢堦〫 涪⦨ˮ孳䚋傠೤ё䍎淉㩴㩢¬ⓀŌ傰䇂揤♢䫍㵦暍ᷚ簔ल&䈠۽咬ሉj࠰|٠怣㣣ߘ䈺滣稠஑⍈3嗩-倥樹ල晨ᙣ㨨㶶挥'䦡ᆤČ᚜䭎ጥ൭䛤戸ƌブ癑࡛ల୻㜰䆆ᅃۄᬠ㗅㶨᯾ࢨ̚ധⴠ㎖㩍䄳唲Ρ㓣殌¾'᫧俣௵墧৘Ჽ氶搰ⓔ䳄⡥Ḷ匱♹砬檊ᦹ਄侥Ợࣄグ䉊㤈γㇻ⑩థ፺䚨磤Ȩ洎ಣǠࡄ㤲䇁栬ጵ䄁㡜ἠ∲䒩5搱ծཌ䖨⦑攡ᛆፔ㉮䥩Ŧ† "
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14bdb5fa77045c18f2505dc5bf49d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PersistWidget(data_values=[{'__id_column': '1', 'Date': 1352419200000, ';Region': 'Salt Lake', 'Place': 'Sunse…"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PR.PersistTable(df_task_1a, df_name=\"df_task_1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f43121e-7493-4db0-a00f-3cef59136676",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1b.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fffac29-972f-4c76-9351-2c954854e7a4",
   "metadata": {},
   "source": [
    "#### Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ded8ee-7828-494d-afeb-8f5b5b5595f1",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰à⬠氤瀹䂃¦¸˰ҁ①าÐɐ໦䓊禳Ӧ攆⩧琫樁拄䨠ዪन㪌糥效桖㖎槻域℁兀†沤挹䠤傡%梄ؠᮬᢛ䑁圌ḀÐ乒䀡ᵼ䠠洠⺱壹溄䅢ᨀ䈩㙐⠠㲸ब佄⍦儂ト桦{్䂼∠⌤䉶汄ၹ䑨凝۠ඊ⡂ڗ䉂Þ⍾捠ೠ䞫づ㕤䄀൐櫻G䀡擑琑䈂㫶ဲ㜧Ꭱ˹ȥᆲ冲椒咃ᨼᐱᒶ䭢䇡Ᏹユ僌䘼ᚦᩐ挬ദ䌜๵䎃ᅄ〴䦈᥃䌰ࡃ㏙㉬ᜨ⊰ᒊ຤惐氮ண成ɁѦቄwၤቘ㲒㙑⏤咤窤䫳䧚ᕄй  "
   },
   "source": [
    "#### **Instructions**\n",
    "1. **Rename Columns:**\n",
    "    - Employ Pandas commands to rename the columns, eliminating the leading \";\" as specified:\n",
    "        - _;Aspect_ → _Aspect_\n",
    "        - _;Region_ → _Region_\n",
    "        - _;Trigger_ → _Trigger_\n",
    "        - _;Weak Layer_ → _Weak Layer_\n",
    "2. **Generate dataframe:**\n",
    "    - Assign the updated dataframe to variable `df_task_1b`.\n",
    "3. **Show Output:**\n",
    "    - Print the head of `df_task_1b` to confirm the updated column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1660a9a4-bbf0-42d9-aacf-ae4c6afa5f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc8043f-28ef-4f56-95cd-9be8ab0acd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns to remove the leading ';'\n",
    "df_task_1b = df_task_1a.rename(columns={\n",
    "    \";Region\": \"Region\",\n",
    "    \";Trigger\": \"Trigger\",\n",
    "    \";Weak Layer\": \"Weak Layer\",\n",
    "    \";Aspect\": \"Aspect\",\n",
    "})\n",
    "\n",
    "df_task_1b.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3875e7fc-ec40-4241-aa94-87b31e59944f",
   "metadata": {},
   "source": [
    "## **Task 1c: Correcting Data Type of 'Depth_inches'**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7eebda-1b60-4bff-89d3-a5548a601b49",
   "metadata": {},
   "source": [
    "#### **Objective**\n",
    "In this task, we will address a data type issue in the `Depth_inches` column of our dataframe. This column is incorrectly formatted as a object (string) due to the presence of the inches symbol `\"`.\n",
    "\n",
    "Remove any inches symbols `\"` from the `Depth_inches` column and convert it to a float data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9bff61-9a8d-4114-97f3-4f6d0cd0e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1b.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c433efa-fcb1-4de7-af16-283cc7f2ac86",
   "metadata": {},
   "source": [
    "### **Persist**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23913ac-ea3c-4ca1-8ac3-07d3026ca76e",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ೠ↺΀Ơ瘢ᠢᠫ‵䁇ፉ䐢怣侽振ၑ䶃᪰঵䂆⹉多䪲┠অҤᴶṂ㊵嘊᭓ㄅ毠㒰䣑Tဠ㚉҃೨ɰ䂠̂҆;䘸Ϥၗ眼䋐Ð䬹†于␠㚠ᝨ沂烒⎁൸憈㬸ᐠṬү䓧Ⴠ椓ᣘ⌚ᆠᛦކ䜱ǁ䅀㖖नຂᩈ桫〦塵偢㶱⢠⾱䂅埦䖃塀㪂ₐ暸ᵽ䀳怠煼砤慸㴻ࠩ㯏姭ঌ䄢䣫䧙㱈刱ㄿᬦ䩫⏃㌱楫磤ⰴຣα晼ਫ䎁㺕䮃Ⴤご䖂᥂挰ы゙㈬ܠ₰ᑊІ僑汮ޯ戩䉱៪怡⹁ᡤ甑擸抯॰ᡬᅓ╄璚╄㈠ "
   },
   "source": [
    "#### **Instructions**\n",
    "1. **Identify Entries with Inches Symbol:**\n",
    "    - Use the interactive table in Persist to look for rows with `\"` in `Depth_inches` column\n",
    "2. **Edit and Correct Entries:**\n",
    "    - Edit the cells to remove the inches symbol from these entries. (e.g. `15\"` → `15`) \n",
    "3. **Convert Data Type:**\n",
    "    - Change the data type of the `Depth_inches` column from string to float.\n",
    "4. **Generate Dataframe:**\n",
    "    - Assign the modified dataframe to a variable `df_task_1c`.\n",
    "5. **Show Output:**\n",
    "    - Display the dtypes of `df_task_1c` to verify the data type correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb9b796-3aa5-4181-bf91-fa8ba7e33c20",
   "metadata": {
    "__has_persist_output": true
   },
   "outputs": [],
   "source": [
    "PR.PersistTable(df_task_1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e34c89-cbda-490d-9848-318cb7c0594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a007a9-dc27-4c45-aa4d-66ff0074e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1c.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9bc0d0-5e3f-4b07-bf14-b83f961eb833",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ೠ↺΀Ơ瘢ᠢᠫ‵䁇ፉ䐢怣侽振ၑ䶃᪰঵䂆⹉多䪲┠অҤᴶṂ㊵嘊᭓ㄅ毠㒰䣑Tဠ㚉҃೨ɰ䂠̂҆;䘸Ϥၗ眼䋐Ð䬹†于␠㚠ᝨ沂烒⎁൸憈㬸ᐠṬү䓧Ⴠ椓ᣘ⌚ᆠᛦކ䜱ǁ䅀㖖नຂᩈ桫〦塵偢㶱⢠⾱䂅埦䖃塀㪂ₐ暸ᵽ䀳怠煼砤慸㴻ࠩ㯏姭ঌ䄢䣫䧙㱈刱ㄿᬦ䩫⏃㌱楫磤ⰴຣα晼ਫ䎁㺕䮃Ⴤご䖂᥂挰ы゙㈬ܠ₰ᑊІ僑汮ޯ戩䉱៪怡⹁ᡤ甑擸抯॰ᡬᅓ╄璚╄㈠ "
   },
   "source": [
    "### **Pandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d843f33c-83c6-4d44-a986-820ff11585dc",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ೠ↺΀Ơ瘢ᠢᠫ‵䁇ፉ䐢怣侽振ၑ䶃᪰঵䂆⹉多䪲┠অҤᴶṂ㊵嘊᭓ㄅ毠㒰䣑Tဠ㚉҃೨ɰ䂠̂҆;䘸Ϥၗ眼䋐Ð䬹†于␠㚠ᝨ沂烒⎁൸憈㬸ᐠṬү䓧Ⴠ椓ᣘ⌚ᆠᛦކ䜱ǁ䅀㖖नຂᩈ桫〦塵偢㶱⢠⾱䂅埦䖃塀㪂ₐ暸ᵽ䀳怠煼砤慸㴻ࠩ㯏姭ঌ䄢䣫䧙㱈刱ㄿᬦ䩫⏃㌱楫磤ⰴຣα晼ਫ䎁㺕䮃Ⴤご䖂᥂挰ы゙㈬ܠ₰ᑊІ僑汮ޯ戩䉱៪怡⹁ᡤ甑擸抯॰ᡬᅓ╄璚╄㈠ "
   },
   "source": [
    "#### **Instructions**\n",
    "\n",
    "1. **Remove Inches Symbol and Correct Format:**\n",
    "    - Use Pandas to replace the inches symbol in the `Depth_inches` column.\n",
    "2. **Convert Data Type:**\n",
    "    - Convert the `Depth_inches` column to float.\n",
    "3. **Generate Dataframe:**\n",
    "    - Save the updated dataframe as `df_task_1c`.\n",
    "4. **Show Output:**\n",
    "    - Print the dtypes of `df_task_1c` to confirm the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1420d86a-7cff-49d8-a92f-6c6fda61e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1b.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d388cb-f5cb-4337-b943-24f8e7a75d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1c = df_task_1b\n",
    "df_task_1c[\"Depth_inches\"] = df_task_1c[\"Depth_inches\"].str.replace('\"', '')\n",
    "df_task_1c[\"Depth_inches\"] = df_task_1c[\"Depth_inches\"].astype(\"Float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856dee6f-706e-4756-b960-2d061436078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1c.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ed0a8-dc0b-4ac8-8afd-b554ea8f4d28",
   "metadata": {},
   "source": [
    "# Task 2: Filtering data\n",
    "\n",
    "In Task 2, we further improve our data by removing outliers and removing certain records to have more consistent data. \n",
    "\n",
    "We will also take a brief look at relations between cause of an avalanche (`Trigger`) and failure point of ice (`Weak Layer`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f25d8f5-98e8-4b0f-9358-ed85f77cbed8",
   "metadata": {},
   "source": [
    "## **Task 2a: Remove Outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53a605-2d10-4457-9625-70ce88f04f3b",
   "metadata": {},
   "source": [
    "#### **Objective**\n",
    "In this task, we address data accuracy by filtering out anomalies in elevation data. We observe some records with elevations outside the plausible range for Utah, suggesting recording errors.\n",
    "\n",
    "Remove avalanche records with elevations below 2000 feet and above 13500 feet, which are outside the realistic range for Utah."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ad44c7-ecd6-4ca9-9f68-0a8d28d0cb48",
   "metadata": {},
   "source": [
    "#### Persist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664c641e-1193-4233-8897-0161f209c86f",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Identify and Remove Anomalies:**\n",
    "    - Interactively select data points with elevations below 2100 feet and above 13500 feet in the Persist Scatterplot.\n",
    "    - Use Persist's interactive features to remove these anomalous records.\n",
    "2. **Generate Dataframe:**\n",
    "    - Assign the cleaned dataframe to a variable `df_task_2a`.\n",
    "3. **Show Output:**\n",
    "    - Display the head of `df_task_2a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d5727a-f059-4bf3-977c-1ce0d6d92eba",
   "metadata": {
    "__has_persist_output": true
   },
   "outputs": [],
   "source": [
    "PR.plot.scatterplot(df_task_1c, \"Elevation_feet:Q\", \"Vertical_inches:Q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0959c1a5-bb43-4c3f-ba26-b20957855f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_2a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd0373e-79d1-44c0-b8bd-2002afe6684a",
   "metadata": {},
   "source": [
    "#### Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f3529a-641b-42b1-9e4d-d51461be760f",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Locate Anomalous Data:**\n",
    "    - Refer to the _seaborn_ scatterplot for `Elevation_feet` vs `Vertical_inches`\n",
    "    - Write code to identify records where `Elevation_feet` is either below 2100 feet or above 13500 feet.\n",
    "3. **Remove Anomalies:**\n",
    "    - Use Pandas commands to filter out these anomalous records from the dataframe.\n",
    "4. **Generate Dataframe:**\n",
    "    - Save the cleaned dataframe as `df_task_2a`.\n",
    "5. **Plot Output:**\n",
    "    - Recreate the scatterplot from step 1 in a new cell using `df_task_2a`.\n",
    "    - Print the head of `df_task_2a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e541870-4719-4bd7-bb67-75270450e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_2a = df_task_1c\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.scatterplot(data=df_task_2a, x='Elevation_feet', y='Vertical_inches')\n",
    "\n",
    "plt.xlabel('Elevation (feet)')\n",
    "plt.ylabel('Vertical Distance (inches)')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0754d690-635e-4f21-b6f8-ddc0ab51b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_2a = df_task_1c[(df_task_1c['Elevation_feet'] >= 2100) & (df_task_1c['Elevation_feet'] <= 13500)]\n",
    "df_task_2a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3fb23c-ad31-43c1-91ea-fb8952b23ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "sns.scatterplot(data=df_task_2a, x='Elevation_feet', y='Vertical_inches')\n",
    "\n",
    "plt.xlabel('Elevation (feet)')\n",
    "plt.ylabel('Vertical Distance (inches)')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b447b862-90c6-4ed7-b48b-baa1cf74ac2d",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰࣠✴ƀචآ൐ୠᣠ⭎¸䚀ᶥ<⋵攴≲䦆ᨐ҅䁲䥈kᑄᄈ夒ર囇⣹嗛➎帣ᢤ䀡傠Ǘ熠㥀ॢȠா䠸ᢀ㜰䁾巒•橀樠Ꮃ䤠ව׷核ᱬ䣘紲₞૦Ԡ޳ŀ凐栠晬╍ಲ䖽䂇栢沀團ᄰ㸸ሪ喊Ⴇ♁䐔粶ᦞΎ刺ࠥ簉窺簲ᖢොሧ҉䃵ⰡḠޅ毗䘤䗾墥୚渍磆搰㣄䆯䌭䊣ᎄ䢩妈䪑䴹ҩ䋫◂რ⢒ઉ⃁⽌囦媍ኘ垤䢠䍤⒂Йᘷ੡䄀҂Ქ⃱琿啡憐㲞ၯ䌨焠ᗿ搫໎㒫ல熪Ņ⎃ऺᥛ⃄ᅠ  "
   },
   "source": [
    "## **Task 2b: Filtering Out Old Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86b30d4-4762-4bc0-bfd3-6f1486b55ad6",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰࣠✴ƀචآ൐ୠᣠ⭎¸䚀ᶥ<⋵攴≲䦆ᨐ҅䁲䥈kᑄᄈ夒ર囇⣹嗛➎帣ᢤ䀡傠Ǘ熠㥀ॢȠா䠸ᢀ㜰䁾巒•橀樠Ꮃ䤠ව׷核ᱬ䣘紲₞૦Ԡ޳ŀ凐栠晬╍ಲ䖽䂇栢沀團ᄰ㸸ሪ喊Ⴇ♁䐔粶ᦞΎ刺ࠥ簉窺簲ᖢොሧ҉䃵ⰡḠޅ毗䘤䗾墥୚渍磆搰㣄䆯䌭䊣ᎄ䢩妈䪑䴹ҩ䋫◂რ⢒ઉ⃁⽌囦媍ኘ垤䢠䍤⒂Йᘷ੡䄀҂Ქ⃱琿啡憐㲞ၯ䌨焠ᗿ搫໎㒫ல熪Ņ⎃ऺᥛ⃄ᅠ  "
   },
   "source": [
    "The interactive barchart below, shows the data aggregated by year. There are noticeably fewer records for the years before 2010.\n",
    "\n",
    "During this subtask we will remove the older records, keeping only the records post 2010."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddf19e6-3600-4f27-b587-885ba7443360",
   "metadata": {},
   "source": [
    "### Persist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b308e8-8437-4146-9ebf-cd121aeb7f9f",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Create and Analyze Bar Chart:**\n",
    "    - Looking at an interactive bar chart in Persist showing the number of avalanches recorded each year, identify the bars showing data we want.\n",
    "2. **Interactive Year Selection:**\n",
    "    - Use a brush to interactively select and remove appropriate records.\n",
    "3. **Generate Dataframe:**\n",
    "    - Assign the refined dataframe to a variable `df_task_2b`.\n",
    "4. **Show Output:**\n",
    "    - Display the head of `df_task_2b` to verify the removal of earlier years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6488acb7-e239-4d7e-92ef-3e9d74c3d823",
   "metadata": {
    "__has_persist_output": true
   },
   "outputs": [],
   "source": [
    "PR.plot.barchart(df_task_2a, \"utcyear(Date):O\", \"count()\", selection_type=\"interval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc3f8a6-09fb-4338-ad2b-af9ecc1b2e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_2b.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc78231-4b97-4d4d-82ee-2a762d20e590",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰Ǡ⬪兠䘤瀥䁍ᴡْ࿪Č⬭总ҡ䲤䫳⩨࣪恆ᖜæⓀŌ傰䏄懠Ɑಥ㕺۬汙㬐਺ဦ䈠ۤ嬬ሉj࠰|ℬ怣㣣ߘ䈺滣䢁6煃ᐠ৵撠۰̊ಭ伆⑶⇐呄䮃ʠϩ䂰㴔屆㹟Ե䏯柧慲డ㙐嬲ᢨҬध⷗ࡣ㌰冦氻U䫄䰷梬䐢紬䎍Sॐ囡׽ण䋔总㘠传Ϛ揿挬ᐎ汣䓼㹮ራ㈨ቺ╯慂厃૵ⴘ嘪⭓炻ࡿ⑁℘ⸯţ✘௨∑㛛㒹ᆢ匋᣹ࢸ䃡ල憰へḨ䕃䢴മ䒀夌✻䐂тྸ•嶢僙戅䢑՞ዂᏴ剶䅭槉ㆰ  "
   },
   "source": [
    "### Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fb76fc-6ea4-4296-8c50-39381f09d9c8",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Create Bar Chart with Seaborn:**\n",
    "    - Use the Seaborn plot with bar chart visualizing the number of avalanches per year. \n",
    "2. **Identify Sparse Years:**\n",
    "    - Based on the bar chart, identify years before 2010 with fewer avalanche records.\n",
    "3. **Code to Filter Out Sparse Years:**\n",
    "    - Write Pandas code to exclude these years from the dataset.\n",
    "4. **Show Output:**\n",
    "    - Print the head of `df_task_2b` and optionally recreate the bar chart to show the dataset focusing on years 2010 and onwards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1769eaa-8327-4aba-86cb-887cb4b669f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_2b = df_task_2a\n",
    "df_task_2b = df_task_2b.convert_dtypes()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x=df_task_2b[\"Date\"].dt.year)\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('# of records')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3a2dc3-1542-407e-a6ad-a090ecfa306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_2b = df_task_2b[df_task_2b[\"Date\"].dt.year >= 2010]\n",
    "df_task_2b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de087e1d-793f-41f6-ba01-0809d0833fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x=df_task_2b[\"Date\"].dt.year)\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('# of records')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e94f0f-6d40-4144-a112-7898433fd662",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_2b.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8fdc8b-168e-40e2-861c-d23095a4a8d8",
   "metadata": {},
   "source": [
    "## **Task 2c: Identifying frequently failing `Weak Layers` for avalanches triggered by _'snowboarders'_ and _'skiers'_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4950defa-280e-4ec5-b59d-c3cd7e2ebcbe",
   "metadata": {},
   "source": [
    "### Persist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd956e34-f1c9-40d3-8702-a2a84e304ca9",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Linked Bar Charts:**\n",
    "    - You will start with two linked interactive bar charts: one for `Trigger` and another for `Weak Layer`.\n",
    "    - Both bar charts show `count` for their respective category.\n",
    "    - You can click on a trigger in the `Trigger` bar chart and the `Weak Layer`' bar chart dynamically updates to show only occurrences corresponding to the selected triggers.\n",
    "2. **Interactive Selection:**\n",
    "    - Interactively select triggers and use the updated `Weak Layer`.\n",
    "3. **Identify the most frequent failure point:**\n",
    "    - Analyze the filtered 'Weak Layer' bar chart to determine the most frequently failed layers for selected category and make a note in a markdown cell about both the name of the layer and frequency.\n",
    "4. **Generate Dataframe and Output:**\n",
    "    - You will not generate any dataframe for this task. NOTE: Please save the notebook after you are finsihed with interactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aef4ea0-bf81-42be-a35a-23e56081f77e",
   "metadata": {
    "__has_persist_output": true
   },
   "outputs": [],
   "source": [
    "pts = alt.selection_point(name=\"selector\", fields=['Trigger'])\n",
    "\n",
    "base = alt.Chart(df_task_2b).encode(y=\"count()\")\n",
    "\n",
    "trigger = base.mark_bar().encode(\n",
    "    x=\"Trigger:N\",\n",
    "    color=alt.condition(pts, \"Trigger:N\", alt.value(\"gray\"))\n",
    ").add_params(pts)\n",
    "\n",
    "weak_layer = base.mark_bar().encode(\n",
    "    x=\"Weak Layer:N\",\n",
    "    color=\"Weak Layer:N\",\n",
    "    tooltip=\"count()\"\n",
    ").transform_filter(\n",
    "    pts\n",
    ")\n",
    "\n",
    "chart = alt.hconcat(\n",
    "    trigger, weak_layer\n",
    ").resolve_scale(\n",
    "    color=\"independent\",\n",
    ")\n",
    "\n",
    "PR.PersistChart(chart, data=df_task_2b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f44925-7703-4844-98ee-d1280f0b10e5",
   "metadata": {},
   "source": [
    "**Task 2c Notes:**\n",
    "\n",
    "- Snowboarder -> New snow/old snow interface (31)\n",
    "- Skiers -> Facets (261)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d12c10-edb7-4c5f-82a9-ca160de89a51",
   "metadata": {},
   "source": [
    "### Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eda516c-ca0c-4ecc-bd48-e40287c4193d",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Identify Predominant Weak Layer:**\n",
    "    - Determine the most common weak layer for these `Snowboarder` and `Skier` triggers for the data.\n",
    "2. **Output:**\n",
    "    - Note in markdown cell both the name of the layer and frequency for each of the above trigger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e7aebd-b709-4b35-80c3-a7c872de6b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_2b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa43696d-904e-4531-9972-551cab614735",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowboarders = df_task_2b[df_task_2b[\"Trigger\"] == \"Snowboarder\"]\n",
    "snowboarders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd93315-4921-4c23-865b-814c02530bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "skiers = df_task_2b[df_task_2b[\"Trigger\"] == \"Skier\"]\n",
    "skiers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e11cad5-70a5-47ce-a4a1-86a1d989d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowboarders[\"Weak Layer\"].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ae661-d569-4f67-b02e-188b2b6f1670",
   "metadata": {},
   "outputs": [],
   "source": [
    "skiers[\"Weak Layer\"].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052071fd-2755-4c50-b65b-d4ade860d910",
   "metadata": {},
   "source": [
    "- snowboarders -> New Snow/Old Snow Interface    (31)\n",
    "- skiers -> Facets                         (261)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a92b8a9-c3a8-4a57-be3b-c9cdc977092c",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰ೠ⬠沈֭⠸恍ff9昽䁮ۦ࠰汬നڀপ㈏䣹厠㬦ተ¶⡨⇱㌀ᅁ╶庳ୖ⹜簧ଭࠣ℠Έ橦औ䁅ШNႦ〡岁䏼ℭ㞁摞+㢱䨠Ԋ牠Έƕ٦枓቙ჿਸ旑䅠Ȅ恨戬പᎭె䝁净儬Ö᡻⌸䐱䘩׍宨⇓ࡱ䍲ච᫲壬จ䙤Ɲڣ圖⍞ᛡ৽ण䃔戋㘠传ϊ揿振䘌汣䓼㹮䘫㈨ቺ⩯↧ᄨXഉ⠅ㅖࢢ侸⇄僡ಖࡢҁ氣С宍劄倶䢡⍤㲂̤㚗٩䄀硂಩⍰琦ᦪ悑屾ᾨႨ㺜*瘪䋇޶⋤ᓘ犠䭳঺᥇⏰ᅠ  "
   },
   "source": [
    "## Task 3: Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da80393-7f4b-4115-a4d1-5b7978e11358",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰â䂬ƀᶷ琶䁋c<搔怳ଚ䠳亡䈤㉕⁖ì⺇⊨攩ᐠ▨戰㑹㧒妰囇⃹喧㝞Ţ∠桠ûு䁔䈠ॢȠந㺸ᢀ盅⻿夣•晀樠Ԃ牠Έƕ稦❳ሪὦ䰼⇑䅠Ȅ恨㙎⌯᪴䶹䈁ℓ琡㙐ᮂ⢨᢬थ⧓ࡢ㌰ሚ璋U䳘䠵欯Т縔絭Sㄭۡ۹ण䉔悊㘠传ϒ橷挣⌏ⱡ䕼庮打㈨ɼ榨慢䃂॑瑐繦┭ڼ㾬⎂厃焸牘榥ᄨ䦯ඦ嘔㗆溄⒀擒摖≦၀ⶃ㧄మޢᄴ䩍རへ∦䯧焤愷䍠Žƀ夅შ㤙༾′⪂㵩掳婊⢄  "
   },
   "source": [
    "### Task 3a: Creating and assigning 'Avalanche Season'**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402412ae-3b84-4fec-9c01-94dd203a7b1f",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰â䂬ƀᶷ琶䁋c<搔怳ଚ䠳亡䈤㉕⁖ì⺇⊨攩ᐠ▨戰㑹㧒妰囇⃹喧㝞Ţ∠桠ûு䁔䈠ॢȠந㺸ᢀ盅⻿夣•晀樠Ԃ牠Έƕ稦❳ሪὦ䰼⇑䅠Ȅ恨㙎⌯᪴䶹䈁ℓ琡㙐ᮂ⢨᢬थ⧓ࡢ㌰ሚ璋U䳘䠵欯Т縔絭Sㄭۡ۹ण䉔悊㘠传ϒ橷挣⌏ⱡ䕼庮打㈨ɼ榨慢䃂॑瑐繦┭ڼ㾬⎂厃焸牘榥ᄨ䦯ඦ嘔㗆溄⒀擒摖≦၀ⶃ㧄మޢᄴ䩍རへ∦䯧焤愷䍠Žƀ夅შ㤙༾′⪂㵩掳婊⢄  "
   },
   "source": [
    "#### **Objective**\n",
    "\n",
    "In this subtask, we'll introduce a new categorical variable named `Avalanche Season` into our dataset. This addition aims to classify each avalanche record into different parts of the avalanche season (Start, Middle, End) based on the month it occurred.\n",
    "\n",
    "Create a new category `Avalanche Season` in the dataset and assign each record to `Start`, `Middle`, or `End` of the avalanche season based on its month."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba10e24c-fa9a-40cf-9246-98d9c20d920b",
   "metadata": {
    "__GENERATED_DATAFRAMES__": "{\"nodeDataframes\":{},\"graphDataframes\":null}",
    "show_aggregate_original": "false",
    "trrack_graph": "ᯡ࠽䈌ʀ匦㢠⹰â䂬ƀᶷ琶䁋c<搔怳ଚ䠳亡䈤㉕⁖ì⺇⊨攩ᐠ▨戰㑹㧒妰囇⃹喧㝞Ţ∠桠ûு䁔䈠ॢȠந㺸ᢀ盅⻿夣•晀樠Ԃ牠Έƕ稦❳ሪὦ䰼⇑䅠Ȅ恨㙎⌯᪴䶹䈁ℓ琡㙐ᮂ⢨᢬थ⧓ࡢ㌰ሚ璋U䳘䠵欯Т縔絭Sㄭۡ۹ण䉔悊㘠传ϒ橷挣⌏ⱡ䕼庮打㈨ɼ榨慢䃂॑瑐繦┭ڼ㾬⎂厃焸牘榥ᄨ䦯ඦ嘔㗆溄⒀擒摖≦၀ⶃ㧄మޢᄴ䩍རへ∦䯧焤愷䍠Žƀ夅შ㤙༾′⪂㵩掳婊⢄  "
   },
   "source": [
    "### Persist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d54d80-ef52-4630-bffb-1e04d9320384",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Visualization**\n",
    "    - We will work with an interactive bar chart in Persist showing the count of avalanche instances aggregated by month.\n",
    "2. **Define Season Categories:**\n",
    "    - Based on typical avalanche seasons in Utah, you will first create a new category called `Avalanche Season` using the `Edit Categories` button in the header.\n",
    "    - In the same menu you will add three options for this category -- `Start`, `Middle`, `End`.\n",
    "3. **Interactive Assignment:**\n",
    "    - Use Persist's interactive features to select each month and assign it to one of the `Avalanche Season` values (Start, Middle, End).\n",
    "    - You should use the following ranges for assigning proper categories:\n",
    "        - `Start` of Season: October, November, December, January, February\n",
    "    \t- `Middle` of Season: March, April, May,\n",
    "    \t- `End` of Season: June, July, August, September\n",
    "4. **Generate Dataframe:**\n",
    "    - Assign the updated dataset to a new variable: `df_task_3a`.\n",
    "5. **Show Output:**\n",
    "    - Print the head of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b62f4c-8841-4f6c-8011-cb2ee31c2c7b",
   "metadata": {
    "__has_persist_output": true
   },
   "outputs": [],
   "source": [
    "select = alt.selection_interval(name=\"selector\", encodings=[\"x\"])\n",
    "\n",
    "chart = alt.Chart(df_task_2b, height=400, width=500).mark_bar().encode(\n",
    "    x=alt.X(\"utcmonth(Date):N\"),\n",
    "    y=\"count()\",\n",
    "    opacity=alt.condition(select, alt.value(1), alt.value(0.2))\n",
    ").add_params(select)\n",
    "\n",
    "PR.PersistChart(chart, data=df_task_2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceea44e-38de-4938-842d-35cefe3fdc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_3a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cef39d-fdc8-4865-bcbc-4702e2bfb8db",
   "metadata": {},
   "source": [
    "### **Pandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f48aaa8-7017-43de-8bd8-190ed9fe4dbd",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Create New Variable:**\n",
    "    - Add a new column `Avalanche Season` to the DataFrame.\n",
    "2. **Assign Category:**\n",
    "    - Using the `month` from the `Date` column assign proper values to the new category.\n",
    "    - You should use the following ranges for assigning proper categories:\n",
    "        - `Start` of Season: October, November, December, January, February\n",
    "    \t- `Middle` of Season: March, April, May,\n",
    "    \t- `End` of Season: June, July, August, September\n",
    "3. **Generate Dataframe:**\n",
    "    - Save the modified DataFrame with the new `Avalanche Season` category to `df_task_3a`.\n",
    "4. **Show Output:**\n",
    "    - Display the head of `df_task_3a` to confirm the addition and categorization of the new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7ccdd7-fccd-44ff-b677-7146cef043c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_3a = df_task_2b.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134214fa-bbe0-4502-b4d8-3498139a2620",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_3a[\"Avalanche Season\"] = \"End\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcd01c0-9371-4e1d-8809-91dce6c1f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_3a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b79dff-5762-4159-9d5a-40f498204e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_3a.loc[df_task_3a[\"Date\"].dt.month.isin([10,11,12,1,2]), \"Avalanche Season\"] = \"Start\"\n",
    "df_task_3a.loc[df_task_3a[\"Date\"].dt.month.isin([3,4,5]), \"Avalanche Season\"] = \"Middle\"\n",
    "\n",
    "df_task_3a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e82a42-5f2f-44e1-b9a5-2e2d403b2ff3",
   "metadata": {},
   "source": [
    "# **Task 3b:## **Analyzing Top Avalanche Trigger by Season**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af40bad3-436e-426c-a02f-f205597e90b5",
   "metadata": {},
   "source": [
    "#### **Objective**\n",
    "In this subtask, we'll analyze which trigger is most prevalent for avalanches in each season phase (Start, Middle, End) using the `Avalanche Season` category created in Task 3a."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914bd750-fbc4-4d0e-aff4-b2d27be38f20",
   "metadata": {},
   "source": [
    "### **Persist**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72455a32-623b-4b87-87d6-ca9c8ebf19e7",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Visualization:**\n",
    "    - We have two linked interactive bar charts: one for 'Avalanche Season' and another for 'Trigger'.\n",
    "    - You can select a category to highlight using the legend for `Avalanche Season` bar chart. The `Trigger` bar chart will dynamically update in response to your selections.\n",
    "2. **Analyze Trigger Data:**\n",
    "    - Observe the filtered `Trigger` bar chart to identify the top trigger for the selected season phase.\n",
    "    - You can hover on the bars to get the exact frequency.\n",
    "3. **Document Findings:**\n",
    "    - Note down the most common trigger for each season phase based on your interactive analysis in a new markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eaff25-74aa-4e43-abbb-19bdfef91064",
   "metadata": {
    "__has_persist_output": true
   },
   "outputs": [],
   "source": [
    "selection = alt.selection_point(name=\"selector\", fields=[\"Avalanche Season\"], bind=\"legend\")\n",
    "base = alt.Chart(df_task_3a)\n",
    "\n",
    "seasons = base.mark_bar().encode(\n",
    "    x=alt.X(\"Avalanche Season:N\").sort([\"Start\", \"Middle\", \"End\"]),\n",
    "    y=\"count()\",\n",
    "    opacity=alt.condition(selection, alt.value(1), alt.value(0.3)),\n",
    "    color=\"Avalanche Season:N\"\n",
    ").add_params(\n",
    "    selection\n",
    ")\n",
    "\n",
    "trigger = base.mark_bar().encode(\n",
    "    x=\"Trigger:N\",\n",
    "    y=\"count()\",\n",
    "    color=\"Trigger:N\",\n",
    "    tooltip=\"count()\"\n",
    ").transform_filter(\n",
    "    selection\n",
    ")\n",
    "\n",
    "chart = seasons | trigger\n",
    "\n",
    "chart = chart.resolve_scale(\n",
    "    color=\"independent\"\n",
    ")\n",
    "\n",
    "PR.PersistChart(chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e87acd-3759-49eb-9e43-d7793672297c",
   "metadata": {},
   "source": [
    "**Task 3b Notes:**\n",
    "\n",
    "- Start of season -> Skiers (591)\n",
    "- Middle of season -> Natural (260)\n",
    "- End of season -> Skiers (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea9687e-d233-4c64-ae1c-d6d8e2b3e564",
   "metadata": {},
   "source": [
    "### **Pandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de570e5-ab49-4e8f-b2b1-86b9a2701ece",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "1. **Analyze Triggers by Season:*\n",
    "\t- Determine the most common trigger for each season.\n",
    "2. **Present Findings:**\n",
    "\t- Note in markdown cell both the name and frequency for each trigger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8967e8a0-84b9-4723-ab6f-c1660c7a46fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_size_df = df_task_3a[[\"Avalanche Season\", \"Trigger\", \"Date\"]].groupby([\"Avalanche Season\", \"Trigger\"]).size().reset_index(name=\"counts\")\n",
    "\n",
    "grouped_size_df.sort_values([\"Avalanche Season\", \"counts\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51a13e2-c66f-45e6-ba89-2ad0c69afa58",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "- End ->\tSkier\t(2)\n",
    "- Middle ->\tNatural\t(260)\n",
    "- Start ->\tSkier\t(591)"
   ]
  }
 ],
 "metadata": {
  "__persist_keys_record": [
   "__GENERATED_DATAFRAMES__",
   "__persist_nb_uuid__",
   "__CATEGORIES_META__",
   "trrack_graph",
   "show_aggregate_origin"
  ],
  "__persist_nb_uuid__": "25d14b25-adc7-4b7a-832d-c2541a5bb5de",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

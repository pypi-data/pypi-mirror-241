# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: watson_nlp_data_model.token.proto
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from watson_nlp_data_model import dependency_pb2 as watson__nlp__data__model_dot_dependency__pb2
from watson_nlp_data_model import partofspeech_pb2 as watson__nlp__data__model_dot_partofspeech__pb2
from watson_nlp_data_model import span_pb2 as watson__nlp__data__model_dot_span__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n!watson_nlp_data_model.token.proto\x12\x15watson_nlp_data_model\x1a&watson_nlp_data_model.dependency.proto\x1a(watson_nlp_data_model.partofspeech.proto\x1a watson_nlp_data_model.span.proto\"\x82\x02\n\x05Token\x12)\n\x04span\x18\x01 \x01(\x0b\x32\x1b.watson_nlp_data_model.Span\x12\x12\n\x05lemma\x18\x02 \x01(\tH\x00\x88\x01\x01\x12@\n\x0epart_of_speech\x18\x03 \x01(\x0e\x32#.watson_nlp_data_model.PartOfSpeechH\x01\x88\x01\x01\x12:\n\ndependency\x18\x04 \x01(\x0b\x32!.watson_nlp_data_model.DependencyH\x02\x88\x01\x01\x12\x10\n\x08\x66\x65\x61tures\x18\x05 \x03(\tB\x08\n\x06_lemmaB\x11\n\x0f_part_of_speechB\r\n\x0b_dependencyb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'watson_nlp_data_model.token_pb2', _globals)
if _descriptor._USE_C_DESCRIPTORS == False:
  DESCRIPTOR._options = None
  _globals['_TOKEN']._serialized_start=177
  _globals['_TOKEN']._serialized_end=435
# @@protoc_insertion_point(module_scope)

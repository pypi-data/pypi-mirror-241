{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# How to modify architectures of fusion models\n\nThis tutorial will show you how to modify the architectures of fusion models.\n\nMore guidance on what can be modified in each fusion model can be found in the `modifying-models` section.\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>Some of the fusion models have been designed to work with specific architectures and there are some restrictions on how they can be modified.\n\n    For example, the channel-wise attention model requires the two modalities to have the same number of layers. Please read the notes section of the fusion model you are interested in to see if there are any restrictions.</p></div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up the experiment\n\nFirst, we will set up the experiment by importing the necessary packages, creating the simulated data, and setting the parameters for the experiment.\n\nFor a more detailed explanation of this process, please see the `train_test_examples` tutorials.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport os\nimport torch.nn as nn\n\nfrom docs.examples import generate_sklearn_simulated_data\nfrom fusilli.data import get_data_module\nfrom fusilli.eval import RealsVsPreds\nfrom fusilli.train import train_and_save_models\n\nfrom fusilli.fusionmodels.tabularimagefusion.denoise_tab_img_maps import DAETabImgMaps\n\nparams = {\n    \"test_size\": 0.2,\n    \"kfold_flag\": False,\n    \"log\": False,\n    \"pred_type\": \"regression\",\n    \"loss_log_dir\": \"loss_logs/modify_layers\",  # where the csv of the loss is saved for plotting later\n    \"checkpoint_dir\": \"checkpoints\",\n    \"loss_fig_path\": \"loss_figures\",\n}\n\n# empty the loss log directory\nfor dir in os.listdir(params[\"loss_log_dir\"]):\n    for file in os.listdir(os.path.join(params[\"loss_log_dir\"], dir)):\n        os.remove(os.path.join(params[\"loss_log_dir\"], dir, file))\n    # remove dir\n    os.rmdir(os.path.join(params[\"loss_log_dir\"], dir))\n\nparams = generate_sklearn_simulated_data(\n    num_samples=500,\n    num_tab1_features=10,\n    num_tab2_features=10,\n    img_dims=(1, 100, 100),\n    params=params,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Specifying the model modifications\n\nNow, we will specify the modifications we want to make to the model.\n\nWe are using the :class:`~fusilli.fusionmodels.tabularimagefusion.denoise_tab_img_maps.DAETabImgMaps` model for this example.\nThis is a subspace-based model which has two PyTorch models that need to be pretrained (a denoising autoencoder for the tabular modality, and a convolutional neural network for the image modality).\nThe fusion model then uses the latent representations of these models to perform the fusion.\n\nThe following modifications can be made to the **pre-trained subspace** model :class:`~fusilli.fusionmodels.tabularimagefusion.denoise_tab_img_maps.denoising_autoencoder_subspace_method`:\n\n.. list-table::\n  :widths: 40 60\n  :header-rows: 1\n  :stub-columns: 0\n\n  * - Attribute\n    - Guidance\n  * - :attr:`.autoencoder.latent_dim`\n    - int\n  * - :attr:`.autoencoder.upsampler`\n    - ``nn.Sequential``\n  * - :attr:`.autoencoder.downsampler`\n    - ``nn.Sequential``\n  * - :attr:`.img_unimodal.img_layers`\n    -\n      * ``nn.Sequential``\n      * Overrides modification of ``img_layers`` made to \"all\"\n  * - :attr:`.img_unimodal.fused_layers`\n    - ``nn.Sequential``\n\nThe following modifications can be made to the **fusion** model :class:`~fusilli.fusionmodels.tabularimagefusion.denoise_tab_img_maps.DAETabImgMaps`:\n\n.. list-table::\n  :widths: 40 60\n  :header-rows: 1\n  :stub-columns: 0\n\n  * - Attribute\n    - Guidance\n  * - :attr:`~.DAETabImgMaps.fusion_layers`\n    - ``nn.Sequential``\n\nLet's change everything that we can!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "layer_mods = {\n    \"DAETabImgMaps\": {\n        \"fusion_layers\": nn.Sequential(\n            nn.Linear(20, 420),\n            nn.ReLU(),\n            nn.Linear(420, 100),\n            nn.ReLU(),\n            nn.Linear(100, 78),\n        ),\n    },\n    \"denoising_autoencoder_subspace_method\": {\n        \"autoencoder.latent_dim\": 150,  # denoising autoencoder latent dim\n        \"autoencoder.upsampler\": nn.Sequential(\n            nn.Linear(20, 80),\n            nn.ReLU(),\n            nn.Linear(80, 100),\n            nn.ReLU(),\n            nn.Linear(100, 150),\n            nn.ReLU(),\n        ),\n        \"autoencoder.downsampler\": nn.Sequential(\n            nn.Linear(150, 100),\n            nn.ReLU(),\n            nn.Linear(100, 80),\n            nn.ReLU(),\n            nn.Linear(80, 20),\n            nn.ReLU(),\n        ),\n        \"img_unimodal.img_layers\": nn.ModuleDict(\n            {\n                \"layer 1\": nn.Sequential(\n                    nn.Conv2d(1, 40, kernel_size=(3, 3), padding=0),\n                    nn.ReLU(),\n                    nn.MaxPool2d((2, 2)),\n                ),\n                \"layer 2\": nn.Sequential(\n                    nn.Conv2d(40, 60, kernel_size=(3, 3), padding=0),\n                    nn.ReLU(),\n                    nn.MaxPool2d((2, 2)),\n                ),\n                \"layer 3\": nn.Sequential(\n                    nn.Conv2d(60, 85, kernel_size=(3, 3), padding=0),\n                    nn.ReLU(),\n                    nn.MaxPool2d((2, 2)),\n                ),\n            }\n        ),\n        \"img_unimodal.fused_layers\": nn.Sequential(\n            nn.Linear(85, 150),\n            nn.ReLU(),\n            nn.Linear(150, 75),\n            nn.ReLU(),\n            nn.Linear(75, 50),\n            nn.ReLU(),\n        ),\n    },\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the data and training the model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# load data\ndatamodule = get_data_module(DAETabImgMaps, params, layer_mods=layer_mods, max_epochs=5, batch_size=64)\n\n# train\ntrained_model_list = train_and_save_models(\n    data_module=datamodule,\n    params=params,\n    fusion_model=DAETabImgMaps,\n    layer_mods=layer_mods,\n    max_epochs=5,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It worked! Let's have a look at the model structure to see what changes have been made.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Subspace Denoising Autoencoder:\\n\", datamodule.subspace_method_train.autoencoder)\nprint(\"Subspace Image CNN:\\n\", datamodule.subspace_method_train.img_unimodal)\nprint(\"Fusion model:\\n\", trained_model_list[0].model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What happens when the modifications are incorrect?\n\nLet's see what happens when we try to modify an **attribute that doesn't exist**.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "layer_mods = {\n    \"denoising_autoencoder_subspace_method\": {\n        \"autoencoder.fake_layers\": nn.Sequential(\n            nn.Linear(20, 420),\n            nn.Linear(420, 100),\n            nn.Linear(100, 78),\n        ),\n    }\n}\n\ntry:\n    datamodule = get_data_module(DAETabImgMaps, params, layer_mods=layer_mods, max_epochs=5, batch_size=64)\nexcept Exception as error:\n    print(error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What about modifying an attribute with the **wrong data type**?\n\n* ``latent_dim`` should be an ``int`` and greater than 0.\n* ``upsampler`` should be an ``nn.Sequential``\n* ``downsampler`` should be an ``nn.Sequential``\n* ``img_layers`` should be an ``nn.ModuleDict``\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "layer_mods = {\n    \"denoising_autoencoder_subspace_method\": {\n        \"autoencoder.latent_dim\": 0,\n    }\n}\n\ntry:\n    get_data_module(DAETabImgMaps, params, layer_mods=layer_mods, max_epochs=5, batch_size=64)\nexcept Exception as error:\n    print(error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "layer_mods = {\n    \"denoising_autoencoder_subspace_method\": {\n        \"autoencoder.upsampler\": nn.Linear(10, 10),\n    }\n}\n\ntry:\n    get_data_module(DAETabImgMaps, params, layer_mods=layer_mods, max_epochs=5, batch_size=64)\nexcept Exception as error:\n    print(error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What about modifying multiple attributes with the **conflicting modifications**?\n\nFor this, let's modify the ``latent_dim`` and the ``upsampler``. of the ``autoencoder`` model.\nThe output of the ``upsampler`` should be the same size as the ``latent_dim``.\nIf we modify both of these to be mismatched, let's see what happens.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "layer_mods = {\n    \"denoising_autoencoder_subspace_method\": {\n        \"autoencoder.latent_dim\": 450,\n        \"autoencoder.upsampler\": nn.Sequential(\n            nn.Linear(10, 100),\n            nn.ReLU(),\n            nn.Linear(100, 200),\n            nn.ReLU(),\n            nn.Linear(200, 300),  # this should be 450 to match the latent_dim\n            nn.ReLU(),\n        )\n    },\n}\n\n# get the data and train the subspace models\ndatamodule = get_data_module(DAETabImgMaps, params, layer_mods=layer_mods, max_epochs=5, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Wow it still works!**\nLet's have a look at what the model structure looks like to see what changes have been made to keep the model valid.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(datamodule.subspace_method_train.autoencoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, a few corrections have been made to the modifications:\n\n* The ``upsampler`` has been modified to have the correct number of nodes in the final layer to match the ``latent_dim``.\n* The ``downsample`` (which we didn't specify a modification for) now has the correct number of nodes in the first layer to match the ``latent_dim``.\n\nIn general, there are checks in the fusion models to make sure that the modifications are valid.\nIf the input number of nodes to a modification is not correct, then the model will automatically calculate the correct number of nodes and correct the modification.\n\nThis is the case for quite a few modifications, but potentially not all of them so please be careful!\nMake sure to print out the model structure to check that the modifications have been made correctly and see what changes have been made to keep the model valid.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# removing checkpoints\nos.remove(params[\"checkpoint_dir\"] + \"/DAETabImgMaps_epoch=04.ckpt\")\nos.remove(params[\"checkpoint_dir\"] + \"/subspace_DAETabImgMaps_DenoisingAutoencoder.ckpt\")\nos.remove(params[\"checkpoint_dir\"] + \"/subspace_DAETabImgMaps_ImgUnimodalDAE.ckpt\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/customising_behaviour/plot_modify_layer_sizes.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_customising_behaviour_plot_modify_layer_sizes.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_customising_behaviour_plot_modify_layer_sizes.py:


How to modify architectures of fusion models
############################################

This tutorial will show you how to modify the architectures of fusion models.

More guidance on what can be modified in each fusion model can be found in the :ref:`modifying-models` section.

.. warning::

    Some of the fusion models have been designed to work with specific architectures and there are some restrictions on how they can be modified.

    For example, the channel-wise attention model requires the two modalities to have the same number of layers. Please read the notes section of the fusion model you are interested in to see if there are any restrictions.

.. GENERATED FROM PYTHON SOURCE LINES 18-25

Setting up the experiment
-------------------------

First, we will set up the experiment by importing the necessary packages, creating the simulated data, and setting the parameters for the experiment.

For a more detailed explanation of this process, please see the :ref:`train_test_examples` tutorials.


.. GENERATED FROM PYTHON SOURCE LINES 25-62

.. code-block:: default


    import matplotlib.pyplot as plt
    import os
    import torch.nn as nn

    from docs.examples import generate_sklearn_simulated_data
    from fusilli.data import get_data_module
    from fusilli.eval import RealsVsPreds
    from fusilli.train import train_and_save_models

    from fusilli.fusionmodels.tabularimagefusion.denoise_tab_img_maps import DAETabImgMaps

    params = {
        "test_size": 0.2,
        "kfold_flag": False,
        "log": False,
        "pred_type": "regression",
        "loss_log_dir": "loss_logs/modify_layers",  # where the csv of the loss is saved for plotting later
        "checkpoint_dir": "checkpoints",
        "loss_fig_path": "loss_figures",
    }

    # empty the loss log directory
    for dir in os.listdir(params["loss_log_dir"]):
        for file in os.listdir(os.path.join(params["loss_log_dir"], dir)):
            os.remove(os.path.join(params["loss_log_dir"], dir, file))
        # remove dir
        os.rmdir(os.path.join(params["loss_log_dir"], dir))

    params = generate_sklearn_simulated_data(
        num_samples=500,
        num_tab1_features=10,
        num_tab2_features=10,
        img_dims=(1, 100, 100),
        params=params,
    )








.. GENERATED FROM PYTHON SOURCE LINES 63-107

Specifying the model modifications
----------------------------------

Now, we will specify the modifications we want to make to the model.

We are using the :class:`~fusilli.fusionmodels.tabularimagefusion.denoise_tab_img_maps.DAETabImgMaps` model for this example.
This is a subspace-based model which has two PyTorch models that need to be pretrained (a denoising autoencoder for the tabular modality, and a convolutional neural network for the image modality).
The fusion model then uses the latent representations of these models to perform the fusion.

The following modifications can be made to the **pre-trained subspace** model :class:`~fusilli.fusionmodels.tabularimagefusion.denoise_tab_img_maps.denoising_autoencoder_subspace_method`:

.. list-table::
  :widths: 40 60
  :header-rows: 1
  :stub-columns: 0

  * - Attribute
    - Guidance
  * - :attr:`.autoencoder.latent_dim`
    - int
  * - :attr:`.autoencoder.upsampler`
    - ``nn.Sequential``
  * - :attr:`.autoencoder.downsampler`
    - ``nn.Sequential``
  * - :attr:`.img_unimodal.img_layers`
    -
      * ``nn.Sequential``
      * Overrides modification of ``img_layers`` made to "all"
  * - :attr:`.img_unimodal.fused_layers`
    - ``nn.Sequential``

The following modifications can be made to the **fusion** model :class:`~fusilli.fusionmodels.tabularimagefusion.denoise_tab_img_maps.DAETabImgMaps`:

.. list-table::
  :widths: 40 60
  :header-rows: 1
  :stub-columns: 0

  * - Attribute
    - Guidance
  * - :attr:`~.DAETabImgMaps.fusion_layers`
    - ``nn.Sequential``

Let's change everything that we can!

.. GENERATED FROM PYTHON SOURCE LINES 107-166

.. code-block:: default


    layer_mods = {
        "DAETabImgMaps": {
            "fusion_layers": nn.Sequential(
                nn.Linear(20, 420),
                nn.ReLU(),
                nn.Linear(420, 100),
                nn.ReLU(),
                nn.Linear(100, 78),
            ),
        },
        "denoising_autoencoder_subspace_method": {
            "autoencoder.latent_dim": 150,  # denoising autoencoder latent dim
            "autoencoder.upsampler": nn.Sequential(
                nn.Linear(20, 80),
                nn.ReLU(),
                nn.Linear(80, 100),
                nn.ReLU(),
                nn.Linear(100, 150),
                nn.ReLU(),
            ),
            "autoencoder.downsampler": nn.Sequential(
                nn.Linear(150, 100),
                nn.ReLU(),
                nn.Linear(100, 80),
                nn.ReLU(),
                nn.Linear(80, 20),
                nn.ReLU(),
            ),
            "img_unimodal.img_layers": nn.ModuleDict(
                {
                    "layer 1": nn.Sequential(
                        nn.Conv2d(1, 40, kernel_size=(3, 3), padding=0),
                        nn.ReLU(),
                        nn.MaxPool2d((2, 2)),
                    ),
                    "layer 2": nn.Sequential(
                        nn.Conv2d(40, 60, kernel_size=(3, 3), padding=0),
                        nn.ReLU(),
                        nn.MaxPool2d((2, 2)),
                    ),
                    "layer 3": nn.Sequential(
                        nn.Conv2d(60, 85, kernel_size=(3, 3), padding=0),
                        nn.ReLU(),
                        nn.MaxPool2d((2, 2)),
                    ),
                }
            ),
            "img_unimodal.fused_layers": nn.Sequential(
                nn.Linear(85, 150),
                nn.ReLU(),
                nn.Linear(150, 75),
                nn.ReLU(),
                nn.Linear(75, 50),
                nn.ReLU(),
            ),
        },
    }








.. GENERATED FROM PYTHON SOURCE LINES 167-169

Loading the data and training the model
---------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 169-183

.. code-block:: default



    # load data
    datamodule = get_data_module(DAETabImgMaps, params, layer_mods=layer_mods, max_epochs=5, batch_size=64)

    # train
    trained_model_list = train_and_save_models(
        data_module=datamodule,
        params=params,
        fusion_model=DAETabImgMaps,
        layer_mods=layer_mods,
        max_epochs=5,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Changed latent_dim in denoising_autoencoder_subspace_method
    Changed upsampler in denoising_autoencoder_subspace_method
    Changed downsampler in denoising_autoencoder_subspace_method
    Changed img_layers in denoising_autoencoder_subspace_method
    Changed fused_layers in denoising_autoencoder_subspace_method
    Reset fused layers in denoising_autoencoder_subspace_method
    Reset fused layers in denoising_autoencoder_subspace_method
    Training: |          | 0/? [00:00<?, ?it/s]    Training:   0%|          | 0/7 [00:00<?, ?it/s]    Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s]     Epoch 0:  14%|█▍        | 1/7 [00:00<00:00, 35.32it/s]    Epoch 0:  14%|█▍        | 1/7 [00:00<00:00, 35.07it/s]    Epoch 0:  29%|██▊       | 2/7 [00:00<00:00, 65.72it/s]    Epoch 0:  29%|██▊       | 2/7 [00:00<00:00, 65.46it/s]    Epoch 0:  43%|████▎     | 3/7 [00:00<00:00, 93.72it/s]    Epoch 0:  43%|████▎     | 3/7 [00:00<00:00, 93.41it/s]    Epoch 0:  57%|█████▋    | 4/7 [00:00<00:00, 119.84it/s]    Epoch 0:  57%|█████▋    | 4/7 [00:00<00:00, 119.51it/s]    Epoch 0:  71%|███████▏  | 5/7 [00:00<00:00, 144.10it/s]    Epoch 0:  71%|███████▏  | 5/7 [00:00<00:00, 143.66it/s]    Epoch 0:  86%|████████▌ | 6/7 [00:00<00:00, 166.21it/s]    Epoch 0:  86%|████████▌ | 6/7 [00:00<00:00, 165.80it/s]    Epoch 0: 100%|██████████| 7/7 [00:00<00:00, 187.43it/s]    Epoch 0: 100%|██████████| 7/7 [00:00<00:00, 186.96it/s]    Epoch 0: 100%|██████████| 7/7 [00:00<00:00, 167.79it/s]    Epoch 0: 100%|██████████| 7/7 [00:00<00:00, 166.67it/s]    Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s]             Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s]    Epoch 1:  14%|█▍        | 1/7 [00:00<00:00, 625.36it/s]    Epoch 1:  14%|█▍        | 1/7 [00:00<00:00, 588.18it/s]    Epoch 1:  29%|██▊       | 2/7 [00:00<00:00, 664.65it/s]    Epoch 1:  29%|██▊       | 2/7 [00:00<00:00, 642.21it/s]    Epoch 1:  43%|████▎     | 3/7 [00:00<00:00, 666.64it/s]    Epoch 1:  43%|████▎     | 3/7 [00:00<00:00, 645.01it/s]    Epoch 1:  57%|█████▋    | 4/7 [00:00<00:00, 636.22it/s]    Epoch 1:  57%|█████▋    | 4/7 [00:00<00:00, 623.92it/s]    Epoch 1:  71%|███████▏  | 5/7 [00:00<00:00, 632.74it/s]    Epoch 1:  71%|███████▏  | 5/7 [00:00<00:00, 624.60it/s]    Epoch 1:  86%|████████▌ | 6/7 [00:00<00:00, 636.87it/s]    Epoch 1:  86%|████████▌ | 6/7 [00:00<00:00, 630.25it/s]    Epoch 1: 100%|██████████| 7/7 [00:00<00:00, 648.56it/s]    Epoch 1: 100%|██████████| 7/7 [00:00<00:00, 642.03it/s]    Epoch 1: 100%|██████████| 7/7 [00:00<00:00, 498.82it/s]    Epoch 1: 100%|██████████| 7/7 [00:00<00:00, 492.33it/s]    Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s]             Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s]    Epoch 2:  14%|█▍        | 1/7 [00:00<00:00, 775.00it/s]    Epoch 2:  14%|█▍        | 1/7 [00:00<00:00, 728.81it/s]    Epoch 2:  29%|██▊       | 2/7 [00:00<00:00, 783.03it/s]    Epoch 2:  29%|██▊       | 2/7 [00:00<00:00, 756.34it/s]    Epoch 2:  43%|████▎     | 3/7 [00:00<00:00, 784.72it/s]    Epoch 2:  43%|████▎     | 3/7 [00:00<00:00, 765.06it/s]    Epoch 2:  57%|█████▋    | 4/7 [00:00<00:00, 752.27it/s]    Epoch 2:  57%|█████▋    | 4/7 [00:00<00:00, 736.10it/s]    Epoch 2:  71%|███████▏  | 5/7 [00:00<00:00, 724.43it/s]    Epoch 2:  71%|███████▏  | 5/7 [00:00<00:00, 713.75it/s]    Epoch 2:  86%|████████▌ | 6/7 [00:00<00:00, 725.78it/s]    Epoch 2:  86%|████████▌ | 6/7 [00:00<00:00, 717.45it/s]    Epoch 2: 100%|██████████| 7/7 [00:00<00:00, 737.30it/s]    Epoch 2: 100%|██████████| 7/7 [00:00<00:00, 730.90it/s]    Epoch 2: 100%|██████████| 7/7 [00:00<00:00, 537.84it/s]    Epoch 2: 100%|██████████| 7/7 [00:00<00:00, 528.45it/s]    Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s]             Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s]    Epoch 3:  14%|█▍        | 1/7 [00:00<00:00, 570.11it/s]    Epoch 3:  14%|█▍        | 1/7 [00:00<00:00, 533.90it/s]    Epoch 3:  29%|██▊       | 2/7 [00:00<00:00, 583.92it/s]    Epoch 3:  29%|██▊       | 2/7 [00:00<00:00, 564.97it/s]    Epoch 3:  43%|████▎     | 3/7 [00:00<00:00, 610.97it/s]    Epoch 3:  43%|████▎     | 3/7 [00:00<00:00, 598.93it/s]    Epoch 3:  57%|█████▋    | 4/7 [00:00<00:00, 634.13it/s]    Epoch 3:  57%|█████▋    | 4/7 [00:00<00:00, 623.55it/s]    Epoch 3:  71%|███████▏  | 5/7 [00:00<00:00, 629.32it/s]    Epoch 3:  71%|███████▏  | 5/7 [00:00<00:00, 620.51it/s]    Epoch 3:  86%|████████▌ | 6/7 [00:00<00:00, 633.12it/s]    Epoch 3:  86%|████████▌ | 6/7 [00:00<00:00, 623.06it/s]    Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 632.39it/s]    Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 626.40it/s]    Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 496.48it/s]    Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 489.24it/s]    Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s]             Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s]    Epoch 4:  14%|█▍        | 1/7 [00:00<00:00, 524.88it/s]    Epoch 4:  14%|█▍        | 1/7 [00:00<00:00, 494.09it/s]    Epoch 4:  29%|██▊       | 2/7 [00:00<00:00, 598.42it/s]    Epoch 4:  29%|██▊       | 2/7 [00:00<00:00, 579.52it/s]    Epoch 4:  43%|████▎     | 3/7 [00:00<00:00, 641.27it/s]    Epoch 4:  43%|████▎     | 3/7 [00:00<00:00, 628.80it/s]    Epoch 4:  57%|█████▋    | 4/7 [00:00<00:00, 677.29it/s]    Epoch 4:  57%|█████▋    | 4/7 [00:00<00:00, 667.22it/s]    Epoch 4:  71%|███████▏  | 5/7 [00:00<00:00, 701.46it/s]    Epoch 4:  71%|███████▏  | 5/7 [00:00<00:00, 693.09it/s]    Epoch 4:  86%|████████▌ | 6/7 [00:00<00:00, 708.22it/s]    Epoch 4:  86%|████████▌ | 6/7 [00:00<00:00, 701.10it/s]    Epoch 4: 100%|██████████| 7/7 [00:00<00:00, 717.80it/s]    Epoch 4: 100%|██████████| 7/7 [00:00<00:00, 709.15it/s]    Epoch 4: 100%|██████████| 7/7 [00:00<00:00, 549.40it/s]    Epoch 4: 100%|██████████| 7/7 [00:00<00:00, 541.92it/s]    Epoch 4: 100%|██████████| 7/7 [00:00<00:00, 422.35it/s]
    Training: |          | 0/? [00:00<?, ?it/s]    Training:   0%|          | 0/7 [00:00<?, ?it/s]    Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s]     Epoch 0:  14%|█▍        | 1/7 [00:00<00:02,  2.56it/s]    Epoch 0:  14%|█▍        | 1/7 [00:00<00:02,  2.56it/s]    Epoch 0:  29%|██▊       | 2/7 [00:00<00:01,  2.77it/s]    Epoch 0:  29%|██▊       | 2/7 [00:00<00:01,  2.77it/s]    Epoch 0:  43%|████▎     | 3/7 [00:01<00:01,  2.70it/s]    Epoch 0:  43%|████▎     | 3/7 [00:01<00:01,  2.70it/s]    Epoch 0:  57%|█████▋    | 4/7 [00:01<00:01,  2.74it/s]    Epoch 0:  57%|█████▋    | 4/7 [00:01<00:01,  2.74it/s]    Epoch 0:  71%|███████▏  | 5/7 [00:01<00:00,  2.83it/s]    Epoch 0:  71%|███████▏  | 5/7 [00:01<00:00,  2.83it/s]    Epoch 0:  86%|████████▌ | 6/7 [00:02<00:00,  2.88it/s]    Epoch 0:  86%|████████▌ | 6/7 [00:02<00:00,  2.88it/s]    Epoch 0: 100%|██████████| 7/7 [00:02<00:00,  3.22it/s]    Epoch 0: 100%|██████████| 7/7 [00:02<00:00,  3.22it/s]    Epoch 0: 100%|██████████| 7/7 [00:02<00:00,  3.00it/s]    Epoch 0: 100%|██████████| 7/7 [00:02<00:00,  3.00it/s]    Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s]            Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s]    Epoch 1:  14%|█▍        | 1/7 [00:00<00:01,  3.18it/s]    Epoch 1:  14%|█▍        | 1/7 [00:00<00:01,  3.17it/s]    Epoch 1:  29%|██▊       | 2/7 [00:00<00:01,  3.15it/s]    Epoch 1:  29%|██▊       | 2/7 [00:00<00:01,  3.15it/s]    Epoch 1:  43%|████▎     | 3/7 [00:00<00:01,  3.17it/s]    Epoch 1:  43%|████▎     | 3/7 [00:00<00:01,  3.17it/s]    Epoch 1:  57%|█████▋    | 4/7 [00:01<00:00,  3.14it/s]    Epoch 1:  57%|█████▋    | 4/7 [00:01<00:00,  3.14it/s]    Epoch 1:  71%|███████▏  | 5/7 [00:01<00:00,  3.10it/s]    Epoch 1:  71%|███████▏  | 5/7 [00:01<00:00,  3.10it/s]    Epoch 1:  86%|████████▌ | 6/7 [00:01<00:00,  3.01it/s]    Epoch 1:  86%|████████▌ | 6/7 [00:01<00:00,  3.01it/s]    Epoch 1: 100%|██████████| 7/7 [00:02<00:00,  3.29it/s]    Epoch 1: 100%|██████████| 7/7 [00:02<00:00,  3.29it/s]    Epoch 1: 100%|██████████| 7/7 [00:02<00:00,  3.07it/s]    Epoch 1: 100%|██████████| 7/7 [00:02<00:00,  3.07it/s]    Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s]            Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s]    Epoch 2:  14%|█▍        | 1/7 [00:00<00:02,  2.00it/s]    Epoch 2:  14%|█▍        | 1/7 [00:00<00:03,  2.00it/s]    Epoch 2:  29%|██▊       | 2/7 [00:00<00:02,  2.40it/s]    Epoch 2:  29%|██▊       | 2/7 [00:00<00:02,  2.40it/s]    Epoch 2:  43%|████▎     | 3/7 [00:01<00:01,  2.45it/s]    Epoch 2:  43%|████▎     | 3/7 [00:01<00:01,  2.45it/s]    Epoch 2:  57%|█████▋    | 4/7 [00:01<00:01,  2.56it/s]    Epoch 2:  57%|█████▋    | 4/7 [00:01<00:01,  2.56it/s]    Epoch 2:  71%|███████▏  | 5/7 [00:01<00:00,  2.68it/s]    Epoch 2:  71%|███████▏  | 5/7 [00:01<00:00,  2.67it/s]    Epoch 2:  86%|████████▌ | 6/7 [00:02<00:00,  2.74it/s]    Epoch 2:  86%|████████▌ | 6/7 [00:02<00:00,  2.74it/s]    Epoch 2: 100%|██████████| 7/7 [00:02<00:00,  3.07it/s]    Epoch 2: 100%|██████████| 7/7 [00:02<00:00,  3.07it/s]    Epoch 2: 100%|██████████| 7/7 [00:02<00:00,  2.87it/s]    Epoch 2: 100%|██████████| 7/7 [00:02<00:00,  2.87it/s]    Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s]            Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s]    Epoch 3:  14%|█▍        | 1/7 [00:00<00:02,  2.98it/s]    Epoch 3:  14%|█▍        | 1/7 [00:00<00:02,  2.98it/s]    Epoch 3:  29%|██▊       | 2/7 [00:00<00:01,  3.08it/s]    Epoch 3:  29%|██▊       | 2/7 [00:00<00:01,  3.08it/s]    Epoch 3:  43%|████▎     | 3/7 [00:00<00:01,  3.10it/s]    Epoch 3:  43%|████▎     | 3/7 [00:00<00:01,  3.10it/s]    Epoch 3:  57%|█████▋    | 4/7 [00:01<00:00,  3.10it/s]    Epoch 3:  57%|█████▋    | 4/7 [00:01<00:00,  3.10it/s]    Epoch 3:  71%|███████▏  | 5/7 [00:01<00:00,  3.09it/s]    Epoch 3:  71%|███████▏  | 5/7 [00:01<00:00,  3.09it/s]    Epoch 3:  86%|████████▌ | 6/7 [00:01<00:00,  3.07it/s]    Epoch 3:  86%|████████▌ | 6/7 [00:01<00:00,  3.07it/s]    Epoch 3: 100%|██████████| 7/7 [00:02<00:00,  3.40it/s]    Epoch 3: 100%|██████████| 7/7 [00:02<00:00,  3.40it/s]    Epoch 3: 100%|██████████| 7/7 [00:02<00:00,  3.12it/s]    Epoch 3: 100%|██████████| 7/7 [00:02<00:00,  3.12it/s]    Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s]            Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s]    Epoch 4:  14%|█▍        | 1/7 [00:00<00:02,  2.39it/s]    Epoch 4:  14%|█▍        | 1/7 [00:00<00:02,  2.39it/s]    Epoch 4:  29%|██▊       | 2/7 [00:00<00:01,  2.63it/s]    Epoch 4:  29%|██▊       | 2/7 [00:00<00:01,  2.63it/s]    Epoch 4:  43%|████▎     | 3/7 [00:01<00:01,  2.66it/s]    Epoch 4:  43%|████▎     | 3/7 [00:01<00:01,  2.66it/s]    Epoch 4:  57%|█████▋    | 4/7 [00:01<00:01,  2.73it/s]    Epoch 4:  57%|█████▋    | 4/7 [00:01<00:01,  2.73it/s]    Epoch 4:  71%|███████▏  | 5/7 [00:01<00:00,  2.77it/s]    Epoch 4:  71%|███████▏  | 5/7 [00:01<00:00,  2.77it/s]    Epoch 4:  86%|████████▌ | 6/7 [00:02<00:00,  2.82it/s]    Epoch 4:  86%|████████▌ | 6/7 [00:02<00:00,  2.82it/s]    Epoch 4: 100%|██████████| 7/7 [00:02<00:00,  3.15it/s]    Epoch 4: 100%|██████████| 7/7 [00:02<00:00,  3.15it/s]    Epoch 4: 100%|██████████| 7/7 [00:02<00:00,  2.95it/s]    Epoch 4: 100%|██████████| 7/7 [00:02<00:00,  2.95it/s]    Epoch 4: 100%|██████████| 7/7 [00:02<00:00,  2.93it/s]
    Changed fusion_layers in DAETabImgMaps
    Reset fused layers in DAETabImgMaps
    Training: |          | 0/? [00:00<?, ?it/s]    Training:   0%|          | 0/7 [00:00<?, ?it/s]    Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s]     Epoch 0:  14%|█▍        | 1/7 [00:00<00:00, 19.01it/s]    Epoch 0:  14%|█▍        | 1/7 [00:00<00:00, 18.89it/s, v_num=Maps]    Epoch 0:  29%|██▊       | 2/7 [00:00<00:00, 22.46it/s, v_num=Maps]    Epoch 0:  29%|██▊       | 2/7 [00:00<00:00, 22.42it/s, v_num=Maps]    Epoch 0:  43%|████▎     | 3/7 [00:00<00:00, 24.41it/s, v_num=Maps]    Epoch 0:  43%|████▎     | 3/7 [00:00<00:00, 24.38it/s, v_num=Maps]    Epoch 0:  57%|█████▋    | 4/7 [00:00<00:00, 25.54it/s, v_num=Maps]    Epoch 0:  57%|█████▋    | 4/7 [00:00<00:00, 25.51it/s, v_num=Maps]    Epoch 0:  71%|███████▏  | 5/7 [00:00<00:00, 26.31it/s, v_num=Maps]    Epoch 0:  71%|███████▏  | 5/7 [00:00<00:00, 26.28it/s, v_num=Maps]    Epoch 0:  86%|████████▌ | 6/7 [00:00<00:00, 26.99it/s, v_num=Maps]    Epoch 0:  86%|████████▌ | 6/7 [00:00<00:00, 26.96it/s, v_num=Maps]    Epoch 0: 100%|██████████| 7/7 [00:00<00:00, 27.97it/s, v_num=Maps]    Epoch 0: 100%|██████████| 7/7 [00:00<00:00, 27.95it/s, v_num=Maps]    Epoch 0: 100%|██████████| 7/7 [00:00<00:00, 25.53it/s, v_num=Maps, val_loss=32.20]    Epoch 0: 100%|██████████| 7/7 [00:00<00:00, 25.49it/s, v_num=Maps, val_loss=32.20, train_loss=23.30]    Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s, v_num=Maps, val_loss=32.20, train_loss=23.30]            Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=Maps, val_loss=32.20, train_loss=23.30]    Epoch 1:  14%|█▍        | 1/7 [00:00<00:00, 28.09it/s, v_num=Maps, val_loss=32.20, train_loss=23.30]    Epoch 1:  14%|█▍        | 1/7 [00:00<00:00, 27.95it/s, v_num=Maps, val_loss=32.20, train_loss=23.30]    Epoch 1:  29%|██▊       | 2/7 [00:00<00:00, 29.06it/s, v_num=Maps, val_loss=32.20, train_loss=23.30]    Epoch 1:  29%|██▊       | 2/7 [00:00<00:00, 28.99it/s, v_num=Maps, val_loss=32.20, train_loss=23.30]    Epoch 1:  43%|████▎     | 3/7 [00:00<00:00, 29.05it/s, v_num=Maps, val_loss=32.20, train_loss=23.30]    Epoch 1:  43%|████▎     | 3/7 [00:00<00:00, 29.00it/s, v_num=Maps, val_loss=32.20, train_loss=23.30]    Epoch 1:  57%|█████▋    | 4/7 [00:00<00:00, 29.31it/s, v_num=Maps, val_loss=32.20, train_loss=23.30]    Epoch 1:  57%|█████▋    | 4/7 [00:00<00:00, 29.27it/s, v_num=Maps, val_loss=32.20, train_loss=23.30]    Epoch 1:  71%|███████▏  | 5/7 [00:00<00:00, 29.65it/s, v_num=Maps, val_loss=32.20, train_loss=23.30]    Epoch 1:  71%|███████▏  | 5/7 [00:00<00:00, 29.62it/s, v_num=Maps, val_loss=32.20, train_loss=23.30]    Epoch 1:  86%|████████▌ | 6/7 [00:00<00:00, 29.71it/s, v_num=Maps, val_loss=32.20, train_loss=23.30]    Epoch 1:  86%|████████▌ | 6/7 [00:00<00:00, 29.68it/s, v_num=Maps, val_loss=32.20, train_loss=23.30]    Epoch 1: 100%|██████████| 7/7 [00:00<00:00, 30.14it/s, v_num=Maps, val_loss=32.20, train_loss=23.30]    Epoch 1: 100%|██████████| 7/7 [00:00<00:00, 30.11it/s, v_num=Maps, val_loss=32.20, train_loss=23.30]    Epoch 1: 100%|██████████| 7/7 [00:00<00:00, 27.25it/s, v_num=Maps, val_loss=31.20, train_loss=23.30]    Epoch 1: 100%|██████████| 7/7 [00:00<00:00, 27.21it/s, v_num=Maps, val_loss=31.20, train_loss=24.70]    Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s, v_num=Maps, val_loss=31.20, train_loss=24.70]            Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=Maps, val_loss=31.20, train_loss=24.70]    Epoch 2:  14%|█▍        | 1/7 [00:00<00:00, 22.79it/s, v_num=Maps, val_loss=31.20, train_loss=24.70]    Epoch 2:  14%|█▍        | 1/7 [00:00<00:00, 22.69it/s, v_num=Maps, val_loss=31.20, train_loss=24.70]    Epoch 2:  29%|██▊       | 2/7 [00:00<00:00, 25.62it/s, v_num=Maps, val_loss=31.20, train_loss=24.70]    Epoch 2:  29%|██▊       | 2/7 [00:00<00:00, 25.55it/s, v_num=Maps, val_loss=31.20, train_loss=24.70]    Epoch 2:  43%|████▎     | 3/7 [00:00<00:00, 26.97it/s, v_num=Maps, val_loss=31.20, train_loss=24.70]    Epoch 2:  43%|████▎     | 3/7 [00:00<00:00, 26.92it/s, v_num=Maps, val_loss=31.20, train_loss=24.70]    Epoch 2:  57%|█████▋    | 4/7 [00:00<00:00, 27.73it/s, v_num=Maps, val_loss=31.20, train_loss=24.70]    Epoch 2:  57%|█████▋    | 4/7 [00:00<00:00, 27.69it/s, v_num=Maps, val_loss=31.20, train_loss=24.70]    Epoch 2:  71%|███████▏  | 5/7 [00:00<00:00, 27.86it/s, v_num=Maps, val_loss=31.20, train_loss=24.70]    Epoch 2:  71%|███████▏  | 5/7 [00:00<00:00, 27.83it/s, v_num=Maps, val_loss=31.20, train_loss=24.70]    Epoch 2:  86%|████████▌ | 6/7 [00:00<00:00, 27.94it/s, v_num=Maps, val_loss=31.20, train_loss=24.70]    Epoch 2:  86%|████████▌ | 6/7 [00:00<00:00, 27.91it/s, v_num=Maps, val_loss=31.20, train_loss=24.70]    Epoch 2: 100%|██████████| 7/7 [00:00<00:00, 28.59it/s, v_num=Maps, val_loss=31.20, train_loss=24.70]    Epoch 2: 100%|██████████| 7/7 [00:00<00:00, 28.57it/s, v_num=Maps, val_loss=31.20, train_loss=24.70]    Epoch 2: 100%|██████████| 7/7 [00:00<00:00, 25.97it/s, v_num=Maps, val_loss=31.60, train_loss=24.70]    Epoch 2: 100%|██████████| 7/7 [00:00<00:00, 25.92it/s, v_num=Maps, val_loss=31.60, train_loss=24.60]    Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s, v_num=Maps, val_loss=31.60, train_loss=24.60]            Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=Maps, val_loss=31.60, train_loss=24.60]    Epoch 3:  14%|█▍        | 1/7 [00:00<00:00, 24.82it/s, v_num=Maps, val_loss=31.60, train_loss=24.60]    Epoch 3:  14%|█▍        | 1/7 [00:00<00:00, 24.64it/s, v_num=Maps, val_loss=31.60, train_loss=24.60]    Epoch 3:  29%|██▊       | 2/7 [00:00<00:00, 24.68it/s, v_num=Maps, val_loss=31.60, train_loss=24.60]    Epoch 3:  29%|██▊       | 2/7 [00:00<00:00, 24.62it/s, v_num=Maps, val_loss=31.60, train_loss=24.60]    Epoch 3:  43%|████▎     | 3/7 [00:00<00:00, 24.93it/s, v_num=Maps, val_loss=31.60, train_loss=24.60]    Epoch 3:  43%|████▎     | 3/7 [00:00<00:00, 24.89it/s, v_num=Maps, val_loss=31.60, train_loss=24.60]    Epoch 3:  57%|█████▋    | 4/7 [00:00<00:00, 25.29it/s, v_num=Maps, val_loss=31.60, train_loss=24.60]    Epoch 3:  57%|█████▋    | 4/7 [00:00<00:00, 25.26it/s, v_num=Maps, val_loss=31.60, train_loss=24.60]    Epoch 3:  71%|███████▏  | 5/7 [00:00<00:00, 25.51it/s, v_num=Maps, val_loss=31.60, train_loss=24.60]    Epoch 3:  71%|███████▏  | 5/7 [00:00<00:00, 25.48it/s, v_num=Maps, val_loss=31.60, train_loss=24.60]    Epoch 3:  86%|████████▌ | 6/7 [00:00<00:00, 25.58it/s, v_num=Maps, val_loss=31.60, train_loss=24.60]    Epoch 3:  86%|████████▌ | 6/7 [00:00<00:00, 25.56it/s, v_num=Maps, val_loss=31.60, train_loss=24.60]    Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 26.47it/s, v_num=Maps, val_loss=31.60, train_loss=24.60]    Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 26.45it/s, v_num=Maps, val_loss=31.60, train_loss=24.60]    Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 24.25it/s, v_num=Maps, val_loss=31.40, train_loss=24.60]    Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 24.21it/s, v_num=Maps, val_loss=31.40, train_loss=24.20]    Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s, v_num=Maps, val_loss=31.40, train_loss=24.20]            Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s, v_num=Maps, val_loss=31.40, train_loss=24.20]    Epoch 4:  14%|█▍        | 1/7 [00:00<00:00, 10.98it/s, v_num=Maps, val_loss=31.40, train_loss=24.20]    Epoch 4:  14%|█▍        | 1/7 [00:00<00:00, 10.91it/s, v_num=Maps, val_loss=31.40, train_loss=24.20]    Epoch 4:  29%|██▊       | 2/7 [00:00<00:00, 12.05it/s, v_num=Maps, val_loss=31.40, train_loss=24.20]    Epoch 4:  29%|██▊       | 2/7 [00:00<00:00, 12.03it/s, v_num=Maps, val_loss=31.40, train_loss=24.20]    Epoch 4:  43%|████▎     | 3/7 [00:00<00:00, 12.81it/s, v_num=Maps, val_loss=31.40, train_loss=24.20]    Epoch 4:  43%|████▎     | 3/7 [00:00<00:00, 12.80it/s, v_num=Maps, val_loss=31.40, train_loss=24.20]    Epoch 4:  57%|█████▋    | 4/7 [00:00<00:00, 14.40it/s, v_num=Maps, val_loss=31.40, train_loss=24.20]    Epoch 4:  57%|█████▋    | 4/7 [00:00<00:00, 14.39it/s, v_num=Maps, val_loss=31.40, train_loss=24.20]    Epoch 4:  71%|███████▏  | 5/7 [00:00<00:00, 15.40it/s, v_num=Maps, val_loss=31.40, train_loss=24.20]    Epoch 4:  71%|███████▏  | 5/7 [00:00<00:00, 15.38it/s, v_num=Maps, val_loss=31.40, train_loss=24.20]    Epoch 4:  86%|████████▌ | 6/7 [00:00<00:00, 14.64it/s, v_num=Maps, val_loss=31.40, train_loss=24.20]    Epoch 4:  86%|████████▌ | 6/7 [00:00<00:00, 14.63it/s, v_num=Maps, val_loss=31.40, train_loss=24.20]    Epoch 4: 100%|██████████| 7/7 [00:00<00:00, 15.07it/s, v_num=Maps, val_loss=31.40, train_loss=24.20]    Epoch 4: 100%|██████████| 7/7 [00:00<00:00, 15.06it/s, v_num=Maps, val_loss=31.40, train_loss=24.20]    Epoch 4: 100%|██████████| 7/7 [00:00<00:00, 14.17it/s, v_num=Maps, val_loss=31.20, train_loss=24.20]    Epoch 4: 100%|██████████| 7/7 [00:00<00:00, 14.15it/s, v_num=Maps, val_loss=31.20, train_loss=24.80]    Epoch 4: 100%|██████████| 7/7 [00:00<00:00, 10.72it/s, v_num=Maps, val_loss=31.20, train_loss=24.80]
    ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
    ┃      Validate metric      ┃       DataLoader 0        ┃
    ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
    │          MAE_val          │     4.404026031494141     │
    │          R2_val           │   -0.000713348388671875   │
    │         val_loss          │     31.2453670501709      │
    └───────────────────────────┴───────────────────────────┘




.. GENERATED FROM PYTHON SOURCE LINES 184-185

It worked! Let's have a look at the model structure to see what changes have been made.

.. GENERATED FROM PYTHON SOURCE LINES 185-190

.. code-block:: default


    print("Subspace Denoising Autoencoder:\n", datamodule.subspace_method_train.autoencoder)
    print("Subspace Image CNN:\n", datamodule.subspace_method_train.img_unimodal)
    print("Fusion model:\n", trained_model_list[0].model)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Subspace Denoising Autoencoder:
     DenoisingAutoencoder(
      (upsampler): Sequential(
        (0): Linear(in_features=10, out_features=80, bias=True)
        (1): ReLU()
        (2): Linear(in_features=80, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=150, bias=True)
        (5): ReLU()
      )
      (downsampler): Sequential(
        (0): Linear(in_features=150, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=80, bias=True)
        (3): ReLU()
        (4): Linear(in_features=80, out_features=10, bias=True)
        (5): ReLU()
      )
      (loss): MSELoss()
    )
    Subspace Image CNN:
     ImgUnimodalDAE(
      (img_layers): ModuleDict(
        (layer 1): Sequential(
          (0): Conv2d(1, 40, kernel_size=(3, 3), stride=(1, 1))
          (1): ReLU()
          (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
        )
        (layer 2): Sequential(
          (0): Conv2d(40, 60, kernel_size=(3, 3), stride=(1, 1))
          (1): ReLU()
          (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
        )
        (layer 3): Sequential(
          (0): Conv2d(60, 85, kernel_size=(3, 3), stride=(1, 1))
          (1): ReLU()
          (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
        )
      )
      (fused_layers): Sequential(
        (0): Linear(in_features=8500, out_features=150, bias=True)
        (1): ReLU()
        (2): Linear(in_features=150, out_features=75, bias=True)
        (3): ReLU()
        (4): Linear(in_features=75, out_features=50, bias=True)
        (5): ReLU()
      )
      (final_prediction): Sequential(
        (0): Linear(in_features=50, out_features=1, bias=True)
      )
    )
    Fusion model:
     DAETabImgMaps(
      (fusion_layers): Sequential(
        (0): Linear(in_features=40390, out_features=420, bias=True)
        (1): ReLU()
        (2): Linear(in_features=420, out_features=100, bias=True)
        (3): ReLU()
        (4): Linear(in_features=100, out_features=78, bias=True)
      )
      (final_prediction): Sequential(
        (0): Linear(in_features=78, out_features=1, bias=True)
      )
    )




.. GENERATED FROM PYTHON SOURCE LINES 191-196

What happens when the modifications are incorrect?
----------------------------------------------------

Let's see what happens when we try to modify an **attribute that doesn't exist**.


.. GENERATED FROM PYTHON SOURCE LINES 196-212

.. code-block:: default


    layer_mods = {
        "denoising_autoencoder_subspace_method": {
            "autoencoder.fake_layers": nn.Sequential(
                nn.Linear(20, 420),
                nn.Linear(420, 100),
                nn.Linear(100, 78),
            ),
        }
    }

    try:
        datamodule = get_data_module(DAETabImgMaps, params, layer_mods=layer_mods, max_epochs=5, batch_size=64)
    except Exception as error:
        print(error)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Layer group autoencoder.fake_layers not found in denoising_autoencoder_subspace_method




.. GENERATED FROM PYTHON SOURCE LINES 213-219

What about modifying an attribute with the **wrong data type**?

* ``latent_dim`` should be an ``int`` and greater than 0.
* ``upsampler`` should be an ``nn.Sequential``
* ``downsampler`` should be an ``nn.Sequential``
* ``img_layers`` should be an ``nn.ModuleDict``

.. GENERATED FROM PYTHON SOURCE LINES 219-231

.. code-block:: default


    layer_mods = {
        "denoising_autoencoder_subspace_method": {
            "autoencoder.latent_dim": 0,
        }
    }

    try:
        get_data_module(DAETabImgMaps, params, layer_mods=layer_mods, max_epochs=5, batch_size=64)
    except Exception as error:
        print(error)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Changed latent_dim in denoising_autoencoder_subspace_method
    ('The latent dimension must be greater than 0. The latent dimension is currently: ', 0)




.. GENERATED FROM PYTHON SOURCE LINES 232-244

.. code-block:: default


    layer_mods = {
        "denoising_autoencoder_subspace_method": {
            "autoencoder.upsampler": nn.Linear(10, 10),
        }
    }

    try:
        get_data_module(DAETabImgMaps, params, layer_mods=layer_mods, max_epochs=5, batch_size=64)
    except Exception as error:
        print(error)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Changed upsampler in denoising_autoencoder_subspace_method
    ('Incorrect data type for the modifications: Attribute upsampler must be of type Sequential, not dtype Linear.',)




.. GENERATED FROM PYTHON SOURCE LINES 245-250

What about modifying multiple attributes with the **conflicting modifications**?

For this, let's modify the ``latent_dim`` and the ``upsampler``. of the ``autoencoder`` model.
The output of the ``upsampler`` should be the same size as the ``latent_dim``.
If we modify both of these to be mismatched, let's see what happens.

.. GENERATED FROM PYTHON SOURCE LINES 250-268

.. code-block:: default


    layer_mods = {
        "denoising_autoencoder_subspace_method": {
            "autoencoder.latent_dim": 450,
            "autoencoder.upsampler": nn.Sequential(
                nn.Linear(10, 100),
                nn.ReLU(),
                nn.Linear(100, 200),
                nn.ReLU(),
                nn.Linear(200, 300),  # this should be 450 to match the latent_dim
                nn.ReLU(),
            )
        },
    }

    # get the data and train the subspace models
    datamodule = get_data_module(DAETabImgMaps, params, layer_mods=layer_mods, max_epochs=5, batch_size=64)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Changed latent_dim in denoising_autoencoder_subspace_method
    Changed upsampler in denoising_autoencoder_subspace_method
    Reset fused layers in denoising_autoencoder_subspace_method
    Training: |          | 0/? [00:00<?, ?it/s]    Training:   0%|          | 0/7 [00:00<?, ?it/s]    Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s]     Epoch 0:  14%|█▍        | 1/7 [00:00<00:00, 279.79it/s]    Epoch 0:  14%|█▍        | 1/7 [00:00<00:00, 269.11it/s]    Epoch 0:  29%|██▊       | 2/7 [00:00<00:00, 322.58it/s]    Epoch 0:  29%|██▊       | 2/7 [00:00<00:00, 316.41it/s]    Epoch 0:  43%|████▎     | 3/7 [00:00<00:00, 331.90it/s]    Epoch 0:  43%|████▎     | 3/7 [00:00<00:00, 327.40it/s]    Epoch 0:  57%|█████▋    | 4/7 [00:00<00:00, 344.65it/s]    Epoch 0:  57%|█████▋    | 4/7 [00:00<00:00, 340.43it/s]    Epoch 0:  71%|███████▏  | 5/7 [00:00<00:00, 343.62it/s]    Epoch 0:  71%|███████▏  | 5/7 [00:00<00:00, 340.65it/s]    Epoch 0:  86%|████████▌ | 6/7 [00:00<00:00, 348.55it/s]    Epoch 0:  86%|████████▌ | 6/7 [00:00<00:00, 345.39it/s]    Epoch 0: 100%|██████████| 7/7 [00:00<00:00, 353.84it/s]    Epoch 0: 100%|██████████| 7/7 [00:00<00:00, 351.49it/s]    Epoch 0: 100%|██████████| 7/7 [00:00<00:00, 278.99it/s]    Epoch 0: 100%|██████████| 7/7 [00:00<00:00, 276.31it/s]    Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s]             Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s]    Epoch 1:  14%|█▍        | 1/7 [00:00<00:00, 366.57it/s]    Epoch 1:  14%|█▍        | 1/7 [00:00<00:00, 346.84it/s]    Epoch 1:  29%|██▊       | 2/7 [00:00<00:00, 346.81it/s]    Epoch 1:  29%|██▊       | 2/7 [00:00<00:00, 340.07it/s]    Epoch 1:  43%|████▎     | 3/7 [00:00<00:00, 364.57it/s]    Epoch 1:  43%|████▎     | 3/7 [00:00<00:00, 359.67it/s]    Epoch 1:  57%|█████▋    | 4/7 [00:00<00:00, 371.92it/s]    Epoch 1:  57%|█████▋    | 4/7 [00:00<00:00, 367.45it/s]    Epoch 1:  71%|███████▏  | 5/7 [00:00<00:00, 374.53it/s]    Epoch 1:  71%|███████▏  | 5/7 [00:00<00:00, 370.13it/s]    Epoch 1:  86%|████████▌ | 6/7 [00:00<00:00, 373.81it/s]    Epoch 1:  86%|████████▌ | 6/7 [00:00<00:00, 371.06it/s]    Epoch 1: 100%|██████████| 7/7 [00:00<00:00, 379.59it/s]    Epoch 1: 100%|██████████| 7/7 [00:00<00:00, 377.20it/s]    Epoch 1: 100%|██████████| 7/7 [00:00<00:00, 310.82it/s]    Epoch 1: 100%|██████████| 7/7 [00:00<00:00, 307.98it/s]    Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s]             Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s]    Epoch 2:  14%|█▍        | 1/7 [00:00<00:00, 369.41it/s]    Epoch 2:  14%|█▍        | 1/7 [00:00<00:00, 351.37it/s]    Epoch 2:  29%|██▊       | 2/7 [00:00<00:00, 383.36it/s]    Epoch 2:  29%|██▊       | 2/7 [00:00<00:00, 374.11it/s]    Epoch 2:  43%|████▎     | 3/7 [00:00<00:00, 392.42it/s]    Epoch 2:  43%|████▎     | 3/7 [00:00<00:00, 386.39it/s]    Epoch 2:  57%|█████▋    | 4/7 [00:00<00:00, 390.48it/s]    Epoch 2:  57%|█████▋    | 4/7 [00:00<00:00, 385.62it/s]    Epoch 2:  71%|███████▏  | 5/7 [00:00<00:00, 386.79it/s]    Epoch 2:  71%|███████▏  | 5/7 [00:00<00:00, 382.96it/s]    Epoch 2:  86%|████████▌ | 6/7 [00:00<00:00, 385.31it/s]    Epoch 2:  86%|████████▌ | 6/7 [00:00<00:00, 381.03it/s]    Epoch 2: 100%|██████████| 7/7 [00:00<00:00, 389.43it/s]    Epoch 2: 100%|██████████| 7/7 [00:00<00:00, 387.30it/s]    Epoch 2: 100%|██████████| 7/7 [00:00<00:00, 328.74it/s]    Epoch 2: 100%|██████████| 7/7 [00:00<00:00, 326.11it/s]    Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s]             Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s]    Epoch 3:  14%|█▍        | 1/7 [00:00<00:00, 346.26it/s]    Epoch 3:  14%|█▍        | 1/7 [00:00<00:00, 331.91it/s]    Epoch 3:  29%|██▊       | 2/7 [00:00<00:00, 381.68it/s]    Epoch 3:  29%|██▊       | 2/7 [00:00<00:00, 371.74it/s]    Epoch 3:  43%|████▎     | 3/7 [00:00<00:00, 363.20it/s]    Epoch 3:  43%|████▎     | 3/7 [00:00<00:00, 357.27it/s]    Epoch 3:  57%|█████▋    | 4/7 [00:00<00:00, 372.17it/s]    Epoch 3:  57%|█████▋    | 4/7 [00:00<00:00, 367.82it/s]    Epoch 3:  71%|███████▏  | 5/7 [00:00<00:00, 378.19it/s]    Epoch 3:  71%|███████▏  | 5/7 [00:00<00:00, 374.73it/s]    Epoch 3:  86%|████████▌ | 6/7 [00:00<00:00, 374.46it/s]    Epoch 3:  86%|████████▌ | 6/7 [00:00<00:00, 371.57it/s]    Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 366.84it/s]    Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 364.24it/s]    Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 305.88it/s]    Epoch 3: 100%|██████████| 7/7 [00:00<00:00, 302.17it/s]    Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s]             Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s]    Epoch 4:  14%|█▍        | 1/7 [00:00<00:00, 350.14it/s]    Epoch 4:  14%|█▍        | 1/7 [00:00<00:00, 335.57it/s]    Epoch 4:  29%|██▊       | 2/7 [00:00<00:00, 319.64it/s]    Epoch 4:  29%|██▊       | 2/7 [00:00<00:00, 305.91it/s]    Epoch 4:  43%|████▎     | 3/7 [00:00<00:00, 327.19it/s]    Epoch 4:  43%|████▎     | 3/7 [00:00<00:00, 322.20it/s]    Epoch 4:  57%|█████▋    | 4/7 [00:00<00:00, 335.66it/s]    Epoch 4:  57%|█████▋    | 4/7 [00:00<00:00, 331.62it/s]    Epoch 4:  71%|███████▏  | 5/7 [00:00<00:00, 329.86it/s]    Epoch 4:  71%|███████▏  | 5/7 [00:00<00:00, 326.73it/s]    Epoch 4:  86%|████████▌ | 6/7 [00:00<00:00, 327.92it/s]    Epoch 4:  86%|████████▌ | 6/7 [00:00<00:00, 324.94it/s]    Epoch 4: 100%|██████████| 7/7 [00:00<00:00, 338.88it/s]    Epoch 4: 100%|██████████| 7/7 [00:00<00:00, 336.72it/s]    Epoch 4: 100%|██████████| 7/7 [00:00<00:00, 279.68it/s]    Epoch 4: 100%|██████████| 7/7 [00:00<00:00, 277.18it/s]    Epoch 4: 100%|██████████| 7/7 [00:00<00:00, 239.89it/s]
    Training: |          | 0/? [00:00<?, ?it/s]    Training:   0%|          | 0/7 [00:00<?, ?it/s]    Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s]     Epoch 0:  14%|█▍        | 1/7 [00:00<00:02,  2.26it/s]    Epoch 0:  14%|█▍        | 1/7 [00:00<00:02,  2.26it/s]    Epoch 0:  29%|██▊       | 2/7 [00:00<00:01,  2.52it/s]    Epoch 0:  29%|██▊       | 2/7 [00:00<00:01,  2.52it/s]    Epoch 0:  43%|████▎     | 3/7 [00:01<00:01,  2.63it/s]    Epoch 0:  43%|████▎     | 3/7 [00:01<00:01,  2.63it/s]    Epoch 0:  57%|█████▋    | 4/7 [00:01<00:01,  2.70it/s]    Epoch 0:  57%|█████▋    | 4/7 [00:01<00:01,  2.70it/s]    Epoch 0:  71%|███████▏  | 5/7 [00:01<00:00,  2.75it/s]    Epoch 0:  71%|███████▏  | 5/7 [00:01<00:00,  2.75it/s]    Epoch 0:  86%|████████▌ | 6/7 [00:02<00:00,  2.76it/s]    Epoch 0:  86%|████████▌ | 6/7 [00:02<00:00,  2.76it/s]    Epoch 0: 100%|██████████| 7/7 [00:02<00:00,  3.06it/s]    Epoch 0: 100%|██████████| 7/7 [00:02<00:00,  3.06it/s]    Epoch 0: 100%|██████████| 7/7 [00:02<00:00,  2.78it/s]    Epoch 0: 100%|██████████| 7/7 [00:02<00:00,  2.78it/s]    Epoch 0:   0%|          | 0/7 [00:00<?, ?it/s]            Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s]    Epoch 1:  14%|█▍        | 1/7 [00:00<00:02,  2.33it/s]    Epoch 1:  14%|█▍        | 1/7 [00:00<00:02,  2.33it/s]    Epoch 1:  29%|██▊       | 2/7 [00:00<00:02,  2.08it/s]    Epoch 1:  29%|██▊       | 2/7 [00:00<00:02,  2.08it/s]    Epoch 1:  43%|████▎     | 3/7 [00:01<00:01,  2.27it/s]    Epoch 1:  43%|████▎     | 3/7 [00:01<00:01,  2.27it/s]    Epoch 1:  57%|█████▋    | 4/7 [00:01<00:01,  2.42it/s]    Epoch 1:  57%|█████▋    | 4/7 [00:01<00:01,  2.42it/s]    Epoch 1:  71%|███████▏  | 5/7 [00:01<00:00,  2.52it/s]    Epoch 1:  71%|███████▏  | 5/7 [00:01<00:00,  2.52it/s]    Epoch 1:  86%|████████▌ | 6/7 [00:02<00:00,  2.59it/s]    Epoch 1:  86%|████████▌ | 6/7 [00:02<00:00,  2.59it/s]    Epoch 1: 100%|██████████| 7/7 [00:02<00:00,  2.89it/s]    Epoch 1: 100%|██████████| 7/7 [00:02<00:00,  2.89it/s]    Epoch 1: 100%|██████████| 7/7 [00:02<00:00,  2.69it/s]    Epoch 1: 100%|██████████| 7/7 [00:02<00:00,  2.69it/s]    Epoch 1:   0%|          | 0/7 [00:00<?, ?it/s]            Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s]    Epoch 2:  14%|█▍        | 1/7 [00:00<00:01,  3.02it/s]    Epoch 2:  14%|█▍        | 1/7 [00:00<00:01,  3.02it/s]    Epoch 2:  29%|██▊       | 2/7 [00:00<00:01,  3.00it/s]    Epoch 2:  29%|██▊       | 2/7 [00:00<00:01,  3.00it/s]    Epoch 2:  43%|████▎     | 3/7 [00:01<00:01,  2.86it/s]    Epoch 2:  43%|████▎     | 3/7 [00:01<00:01,  2.85it/s]    Epoch 2:  57%|█████▋    | 4/7 [00:01<00:01,  2.83it/s]    Epoch 2:  57%|█████▋    | 4/7 [00:01<00:01,  2.83it/s]    Epoch 2:  71%|███████▏  | 5/7 [00:01<00:00,  2.84it/s]    Epoch 2:  71%|███████▏  | 5/7 [00:01<00:00,  2.84it/s]    Epoch 2:  86%|████████▌ | 6/7 [00:02<00:00,  2.87it/s]    Epoch 2:  86%|████████▌ | 6/7 [00:02<00:00,  2.87it/s]    Epoch 2: 100%|██████████| 7/7 [00:02<00:00,  3.20it/s]    Epoch 2: 100%|██████████| 7/7 [00:02<00:00,  3.20it/s]    Epoch 2: 100%|██████████| 7/7 [00:02<00:00,  2.95it/s]    Epoch 2: 100%|██████████| 7/7 [00:02<00:00,  2.95it/s]    Epoch 2:   0%|          | 0/7 [00:00<?, ?it/s]            Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s]    Epoch 3:  14%|█▍        | 1/7 [00:00<00:02,  2.98it/s]    Epoch 3:  14%|█▍        | 1/7 [00:00<00:02,  2.98it/s]    Epoch 3:  29%|██▊       | 2/7 [00:00<00:01,  2.96it/s]    Epoch 3:  29%|██▊       | 2/7 [00:00<00:01,  2.96it/s]    Epoch 3:  43%|████▎     | 3/7 [00:01<00:01,  2.98it/s]    Epoch 3:  43%|████▎     | 3/7 [00:01<00:01,  2.98it/s]    Epoch 3:  57%|█████▋    | 4/7 [00:01<00:01,  2.94it/s]    Epoch 3:  57%|█████▋    | 4/7 [00:01<00:01,  2.94it/s]    Epoch 3:  71%|███████▏  | 5/7 [00:01<00:00,  2.91it/s]    Epoch 3:  71%|███████▏  | 5/7 [00:01<00:00,  2.91it/s]    Epoch 3:  86%|████████▌ | 6/7 [00:02<00:00,  2.93it/s]    Epoch 3:  86%|████████▌ | 6/7 [00:02<00:00,  2.93it/s]    Epoch 3: 100%|██████████| 7/7 [00:02<00:00,  3.26it/s]    Epoch 3: 100%|██████████| 7/7 [00:02<00:00,  3.26it/s]    Epoch 3: 100%|██████████| 7/7 [00:02<00:00,  3.00it/s]    Epoch 3: 100%|██████████| 7/7 [00:02<00:00,  3.00it/s]    Epoch 3:   0%|          | 0/7 [00:00<?, ?it/s]            Epoch 4:   0%|          | 0/7 [00:00<?, ?it/s]    Epoch 4:  14%|█▍        | 1/7 [00:00<00:02,  2.75it/s]    Epoch 4:  14%|█▍        | 1/7 [00:00<00:02,  2.75it/s]    Epoch 4:  29%|██▊       | 2/7 [00:00<00:01,  2.88it/s]    Epoch 4:  29%|██▊       | 2/7 [00:00<00:01,  2.88it/s]    Epoch 4:  43%|████▎     | 3/7 [00:01<00:01,  2.92it/s]    Epoch 4:  43%|████▎     | 3/7 [00:01<00:01,  2.92it/s]    Epoch 4:  57%|█████▋    | 4/7 [00:01<00:01,  2.96it/s]    Epoch 4:  57%|█████▋    | 4/7 [00:01<00:01,  2.96it/s]    Epoch 4:  71%|███████▏  | 5/7 [00:01<00:00,  2.97it/s]    Epoch 4:  71%|███████▏  | 5/7 [00:01<00:00,  2.97it/s]    Epoch 4:  86%|████████▌ | 6/7 [00:02<00:00,  2.98it/s]    Epoch 4:  86%|████████▌ | 6/7 [00:02<00:00,  2.98it/s]    Epoch 4: 100%|██████████| 7/7 [00:02<00:00,  3.32it/s]    Epoch 4: 100%|██████████| 7/7 [00:02<00:00,  3.32it/s]    Epoch 4: 100%|██████████| 7/7 [00:02<00:00,  3.07it/s]    Epoch 4: 100%|██████████| 7/7 [00:02<00:00,  3.06it/s]    Epoch 4: 100%|██████████| 7/7 [00:02<00:00,  3.05it/s]




.. GENERATED FROM PYTHON SOURCE LINES 269-271

**Wow it still works!**
Let's have a look at what the model structure looks like to see what changes have been made to keep the model valid.

.. GENERATED FROM PYTHON SOURCE LINES 271-274

.. code-block:: default


    print(datamodule.subspace_method_train.autoencoder)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    DenoisingAutoencoder(
      (upsampler): Sequential(
        (0): Linear(in_features=10, out_features=100, bias=True)
        (1): ReLU()
        (2): Linear(in_features=100, out_features=200, bias=True)
        (3): ReLU()
        (4): Linear(in_features=200, out_features=450, bias=True)
        (5): ReLU()
      )
      (downsampler): Sequential(
        (0): Linear(in_features=450, out_features=256, bias=True)
        (1): ReLU()
        (2): Linear(in_features=256, out_features=128, bias=True)
        (3): ReLU()
        (4): Linear(in_features=128, out_features=10, bias=True)
        (5): ReLU()
      )
      (loss): MSELoss()
    )




.. GENERATED FROM PYTHON SOURCE LINES 275-285

As you can see, a few corrections have been made to the modifications:

* The ``upsampler`` has been modified to have the correct number of nodes in the final layer to match the ``latent_dim``.
* The ``downsample`` (which we didn't specify a modification for) now has the correct number of nodes in the first layer to match the ``latent_dim``.

In general, there are checks in the fusion models to make sure that the modifications are valid.
If the input number of nodes to a modification is not correct, then the model will automatically calculate the correct number of nodes and correct the modification.

This is the case for quite a few modifications, but potentially not all of them so please be careful!
Make sure to print out the model structure to check that the modifications have been made correctly and see what changes have been made to keep the model valid.

.. GENERATED FROM PYTHON SOURCE LINES 285-290

.. code-block:: default


    # removing checkpoints
    os.remove(params["checkpoint_dir"] + "/DAETabImgMaps_epoch=04.ckpt")
    os.remove(params["checkpoint_dir"] + "/subspace_DAETabImgMaps_DenoisingAutoencoder.ckpt")
    os.remove(params["checkpoint_dir"] + "/subspace_DAETabImgMaps_ImgUnimodalDAE.ckpt")








.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 31.362 seconds)


.. _sphx_glr_download_auto_examples_customising_behaviour_plot_modify_layer_sizes.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_modify_layer_sizes.py <plot_modify_layer_sizes.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_modify_layer_sizes.ipynb <plot_modify_layer_sizes.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
